---
title: "Data programming"
subtitle: "Data Analysis in R"
title-slide-attributes:
  data-background-image: img/data-science-2.jpeg
  data-background-size: cover
  data-background-opacity: "0.2"
author: "Master in Computational Social Sciences • 2023-2024"
affiliation: UC3M
lang: es
language: custom_lang.yml
format: 
  revealjs:
    theme: [default, style.scss]
    chalkboard: true
    multiplex: true
    menu:
      side: left
      width: normal
    footer: "[<strong>Javier Álvarez Liébana</strong>](...) • Master in Computational Social Sciences • 2023-2024"
    slide-number: c/t
execute:
  echo: true
---

# Welcome to R!

[**Put your spreadsheets aside**]{style="color:#444442;"}

---

## Hi!

[**Mail**]{.hl-green}: **<javiealv@pa.uc3m.es>** and **<javalv09@ucm.es>**. 

::: columns
::: {.column width="30%"}
![](img/me.jpeg)
:::

::: {.column width="70%"}
::: incremental
- [**Javier Álvarez Liébana**]{.hl-yellow} from Carabanchel (Madrid).

- Degree in Mathematics (UCM). [**PhD in Statistics**]{.hl-yellow} (UGR).

- In charge of  [**data visualization and analysis for the Principality of Asturias (2021-2022)**]{.hl-yellow} during the COVID pandemic.

- Member of the [**Spanish Society of Statistics and OR**]{.hl-yellow} and the [**Spanish Royal Mathematical Society**]{.hl-yellow}.

:::
:::
:::


. . .

Currently, [**researcher and lecturer at the Faculty of Statistics of the UCM**]{.hl-yellow}. Disseminating via [**Twitter**](https://twitter.com/dadosdelaplace) and [**Instagram**](https://instagram.com/javieralvarezliebana).

---

## Goals

::: columns
::: {.column width="37%"}
![](https://assets-global.website-files.com/6092cb6b4ac959f39728dd26/6188a97fa499b5fbfe410417_target%20(1).png)
:::

::: {.column width="63%"}
::: incremental

- Take away the [**fear of programming errors**]{.hl-yellow} → learn to program by programming

- Understanding [**basic R concepts**]{.hl-yellow} from scratch → learning to abstract ideas and algorithms

- Utility of programming → [**reproducible**, **transparent**]{.hl-yellow} and maintainable workflows.

- Introduction to [**analysis and preprocessing**]{.hl-yellow} of data → `{tidyverse}`.

- Handling [**advanced data types**]{.hl-yellow} → `{forcats}`, `{lubridate}` and `{purrr}` packages

:::
:::
:::

---

## Evaluation

- [**Attendance and individual participation**]{.hl-yellow} in the class (10%)

. . .

- [**Individual work done during the course**]{.hl-yellow} (35%). Throughout the course there are [**3 individual task submissions**]{.hl-purple}.

. . .


- [**Group work**]{.hl-yellow} done at the end of the course (30%) (between 2 and 4 people), in which the analysis of a real case must be presented.


---

## Plannning

::: column-screen-inset-right
::: {style="font-size:20px"}
|  LESSON | WEEK | DATE | TOPIC | SCRIPTS | EJ. | CASO PRÁCTICO | ENTREGA | 
|:------:|:--------:|:--------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
|     [1](#clase-1-primeros-pasos)      | S1     | 14 sep |                 R base programming                   | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno)  [💻](#tu-turno-1) [💻](#tu-turno-1a) |       [🐣](#caso-práctico-1)                  |         | 
|     [2](#clase-2)      | S2     | 26 sep |                 First databases: tibbles and tidy data       | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |      [💻](#tu-turno-tibble) [💻](#tu-turno-2)    |  [🐣](#caso-práctico-2) [🐣](#caso-práctico-3)  |         |     
|     [3](#clase-3)      | S3    | 28 sep |     Tidyverse: rows | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-3) [💻](#tu-turno-3a) [💻](#tu-turno-3b)      |  [🐣](#caso-práctico-3)  |         |   
|     [4](#clase-4)      | S4    | 5 oct |   Tidyverse: columns   | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-4a)  [💻](#tu-turno-4b) [💻](#tu-turno-4c)      |  [🐣](#caso4) [🐣](#caso4a) [🐣](#caso4b)  |         | 
|     [5](#clase-5)      | S5   | 10 oct |        Tidyverse: summarising. Rmarkdown    | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-5a)  [💻](#tu-turno-5b)      |  [🐣](#caso5a) [🐣](#caso5b)  |         | 
|     [6](#clase-6)      | S6    | 19 oct |     Import/export | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-4)      |  [🐣](#caso-práctico-3)  |         | 
|     [7](#clase-7)      | S7    | 24 oct |     Functions | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-4)      |  [🐣](#caso-práctico-3)  |    
|     [8](#clase-8)      | S7    | 26 oct |   Control flow structures. Factors, lists and strings   | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-4)      |  [🐣](#caso-práctico-3)  |   | 
|     [9](#clase-9)      | S10   | 16 nov |        Joins and SQL | [📝](https://github.com/dadosdelaplace/mucss-data-programming/material/scripts)  |       [💻](#tu-turno-4)      |  [🐣](#caso-práctico-3)  |         | 

:::
:::

---

## Plannning


* Individual Task I (10%): 24th October (R base, databases, tidydata)

* Individual Task II (25%): 5th December (Tidyverse, control flow structures, functions, lists, etc)

* Group Task  (30%)

---

## Materials

* [**Slides**]{.hl-yellow}: the slides that we will use in the classroom throughout the course, structured by classes, will be available and updated at **<https://javieralvarezliebana.es/mucss-data-programming/slides>**. 

In the slide menu (bottom left) you have an [**option to download them in pdf**]{.hl-yellow} under `Tools` (tip: do not do this until the end of the course as they will be modified).

  
&nbsp;

* [**Package summaries**]{.hl-yellow}: [**package cheatsheets**](https://github.com/dadosdelaplace/mucss-data-programming/tree/main/cheatsheets) in .pdf format


# Lesson 1: R base programming {#clase-1-primeros-pasos}

[**Introduction to R and RStudio ecosystems. Working with projects. First uses of functions and packages. Basic data types.**]{style="color:#444442;"}


---

## Requirements

For the course the only requirements will be:

1. [**Internet connection**]{.hl-yellow} (for downloading some data and packages).

2. [**Installing R**]{.hl-yellow}[: it will be our language. The download will be done (free of charge) from <https://cran.r-project.org/>]{.fragment .fade-in}


::: {.fragment .fade-in}
3.  [**Installing RStudio**]{.hl-yellow} from <https://posit.co/download/rstudio-desktop/>
:::

::: columns
::: {.column width="50%"}
![](img/cranR.jpg){width="420"}
:::

::: {.column width="50%"}
![](img/rstudio.jpg){width="420"}
:::
:::

---

::: columns
::: {.column width="50%"}
![](img/gramatica.webp){width="400"}
:::

::: {.column width="50%"}
![](img/word.jpg){width="470"}
:::
:::

::: {.fragment .fade-in-then-out}
We will program as we write (English, for example) → `R` is the [**language**]{.hl-yellow}
:::

::: {.fragment .fade-up}
- We will need a [**grammar**]{.hl-yellow} (`R`)

::: {.fragment .fade-in}
- And an environment, for example a [**Word**]{.hl-yellow} (`RStudio`), to write it in.
:::
:::

---

## Installing R

The `R` language will be our [**grammar and spelling**]{.hl-yellow} (our rules).

::: incremental
- [**Step 1**]{.hl-yellow}: go to <https://cran.r-project.org/> and select your operating system.

- [**Step 2**]{.hl-yellow}: for Mac just click on the **.pkg file**, and open it once downloaded. For Windows systems, click on **install R for the first time** and then on **Download R for Windows**. Once downloaded, open it like any other installation file.

- [**Step 3**]{.hl-yellow}: open the installation executable.
:::

. . .

::: callout-warning
## Warning
Whenever you download something from CRAN (either R itself or a package), [**make sure you have an internet connection**]{.hl-orange}.
:::

---

## First steps

::: columns
::: {.column width="65%"}
To check that it has been installed correctly, after opening `R`, you should see a **white screen** similar to this one.

That "white screen" is called [**console**]{.hl-yellow} and we can make a first use of it as a **calculator**.
:::

::: {.column width="35%"}
![](img/consola.jpg){width="200"}
:::
:::

. . .

[**Idea**]{.hl-yellow}: let us define a variable called `a`, and it will be assigned the value `1` (type the code below in the console and hit "enter").

```{r}
#| code-line-numbers: "1"
a <- 1
```

---

## First steps

::: columns
::: {.column width="65%"}
To check that it has been installed correctly, after opening `R`, you should see a **white screen** similar to this one.

That "white screen" is called [**console**]{.hl-yellow} and we can make a first use of it as a **calculator**.
:::

::: {.column width="35%"}
![](img/consola.jpg){width="200"}
:::
:::

[**Idea**]{.hl-yellow}: we will define another variable called `b` and assign it the value `2`.


```{r}
#| code-line-numbers: "2"
a <- 1
b <- 2
```

. . .

::: callout-note
## Note that...

In `R` we use `<-` as an arrow: the variable to the left of the arrow is assigned the value to the right (e.g. `a <- 1`).

:::

---

## First steps

::: columns
::: {.column width="65%"}
To check that it has been installed correctly, after opening `R`, you should see a **white screen** similar to this one.

That "white screen" is called [**console**]{.hl-yellow} and we can make a first use of it as a **calculator**.
:::

::: {.column width="35%"}
![](img/consola.jpg){width="270"}
:::
:::

[**Idea**]{.hl-yellow}: we will do the sum `a + b` and it will return its result.

```{r}
#| code-line-numbers: "3"
a <- 1
b <- 2
a + b
```

---

## Installing R Studio

`RStudio` will be the [**Word**]{.hl-yellow} that we will use to write (what is known as an [**IDE: integrated development environment**]{.hl-yellow}).

::: incremental
- [**Step 1**]{.hl-yellow}: go to the [official RStudio website](https://posit.co/download/rstudio-desktop/) (now called Posit) and select the free download.

- [**Step 2**]{.hl-yellow}: select the executable that appears according to your operating system.

- [**Step 3**]{.hl-yellow}: after downloading the executable, open it like any other executable and let the installation finish.
:::

---

## Pane layout in RStudio

When you open `RStudio` you will probably have three windows:

- [**Console**]{.hl-yellow}: this is the name to call the big window that takes up a good part of your screen. Try writing the same code as before (the sum of the variables) in it. The console will be where we will **execute commands and show results**.

![](img/consola_rstudio.jpg){width="420"}

---

## Pane layout in RStudio

When you open `RStudio` you will probably have three windows:

-   [**Environment**]{.hl-yellow}: the small screen (you can adjust the margins) located at the upper right part. It will show us the **variables we have defined**.

![](img/environment.jpg){width="420"}

---

## Pane layout in RStudio

When you open `RStudio` you will probably have three windows:

-   [**Multi-purpose panel**]{.hl-yellow}: the window at the bottom right will not only be used to search for **function help**, but also to **view graphics**.

![](img/multiusos.jpg){width="420"}

---

## Why R?

![](img/meme_barco.jpg)

---

## Why R?

`R` is the [**main statistical language**]{.hl-yellow}, created by and for statisticians, with 5 fundamental advantages [**over Excel**]{.hl-red}:

::: incremental

- [**Programming language**]{.hl-yellow}: obviousness → [**replicable**]{.hl-purple} analysis.

- [**Free of charge**]{.hl-yellow}: the philosophy of the `R` community is code sharing under **copyleft** → [**ethical use of public money**]{.hl-purple}

- [**Open source**]{.hl-yellow}: not only is it free but it allows free access to other people's code, even to **own source code** → [**flexibility and transparency**]{.hl-purple}

- [**Modular language**]{.hl-yellow}: there are other people's code that we can reuse (almost 20 000 [**packages**]{.hl-yellow}) → [**time-saving**]{.hl-purple}

- [**High-level language**]{.hl-yellow}

:::

---

## Why R?

![](img/incel_excel.png)

---

## Why programming?

- [**Automate**]{.hl-yellow} → it will allow you to automate recurring tasks.

- [**Replicability**]{.hl-yellow} → you will be able to replicate your analysis always in the same way.

- [**Flexibility**]{.hl-yellow} → you will be able to adapt the software to your needs.

- [**Transparency**]{.hl-yellow} → it could be audited by the community.

![](img/the_general_problem.png)

---

## Main idea: packages

One of the key ideas of `R` is the [**use of packages**]{.hl-yellow}: codes that other people have implemented to **solve a problem**.

::: columns
::: {.column width="35%"}
![](img/paquetes.png)
:::

::: {.column width="65%"}
::: {.fragment fragment-index="1"}
- [**Installing**]{.hl-yellow}: download the codes from the web (internet required) → [**"buy a book"**]{.hl-purple}, only once (per computer)

```{r}
#| eval: false
install.packages("ggplot2")
```
:::

::: {.fragment fragment-index="2"}
- [**Loading**]{.hl-yellow}: after downloading the package, we indicate which packages we want to use each time we open `RStudio` → [**bring the book off the shelf**]{.hl-purple}

```{r}
#| eval: false
library(ggplot2)
```
:::
:::
:::

---

## Main idea: packages

::: columns
::: {.column width="35%"}
![](img/paquetes.png)
:::

::: {.column width="65%"}
Once installed, there are two ways to use a package (bring it off the shelf)

::: {.fragment fragment-index="1"}
-   [**The whole package**]{.hl-yellow}: with `library()`, using the package name without quotes, we load into our session the [**whole book**]{.hl-purple}.

```{r}
#| eval: false
library(ggplot2)
```
:::

::: {.fragment fragment-index="2"}
- [**Some particular functions**]{.hl-yellow} using `package::function` we indicate that we only want a [**concrete page of that book**]{.hl-purple}.

```{r}
#| eval: false
ggplot2::geom_point()
```
:::
:::
:::

---

## You will be wrong

During your learning process, it is going to be very common that things don't go right the first time → [**you will make mistakes**]{.hl-yellow}. Not only will it be important to assume this, but it is [**important to read the error messages**]{.hl-yellow} to learn from them.

. . .

-   [**Error messages**]{.hl-red}: preceded by **"Error in... "** and will be those failures that [**prevent execution**]{.hl-red}.

```{r}
#| error: true
"a" + 1 
```

. . .

-   [**Warning messages**]{.hl-orange}: preceded by **"Warning in... "** are the most sensitive (possible) failures since they are inconsistencies that [**do not prevent execution**]{.hl-orange}.

```{r}
#| warning: true
# Code is ok but the result provided a NaN value, **Not A Number**, a value that is not a (real) number
sqrt(-1)
```

---

## Scripts (.R files)

::: columns
::: {.column width="35%"}
![](img/abrir_script.jpg){width="350"}
:::

::: {.column width="65%"}
A [**script**]{.hl-yellow} will be the document in which we program, our `.doc` file (here with `.R` extension) where we will write the commands. To **open our first script**, click in the menu on `File < New File < R Script`.
:::
:::

::: callout-warning
## Be careful

It is important **not to overuse the console**: everything you do not write in a script, when you close, [**you will have lost it**]{.hl-orange}.
:::

---

## Executing the first script

Now we have a **fourth window**: the window where we [**write our codes**]{.hl-yellow}. How to run it?

. . .

1. **We write** the code to execute.

. . .

2.  **Save** the .R file by clicking on `Save current document`.

. . .

3.  The code is not executed unless we tell it to do so. We have three options:

- [**Copy and paste**]{.hl-yellow} into console.
- [**Select lines**]{.hl-yellow} and `Ctrl+Enter`.
- [**Enable Source on save**]{.hl-yellow} to the right of save: it not only saves but executes the **whole code**.

---

## 💻 Your turn {#tu-turno}

[**Execute your first script**: create a script from scratch, program as indicated below and execute it (in the 3 possible ways)]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Define a variable named `a` and whose value is -1.

```{r}
#| code-fold: true
a <- -1
```

### [**Exercise 2**]{.hl-yellow}

📝 Add below another line to define a variable `b` with value 5. Then multiply both variables.

```{r}
#| code-fold: true
#| eval: false
b <- 5
a * b # no saved
mult <- a * b # saved
```

### [**Exercise 3**]{.hl-yellow}

📝 Modify the code below to define two variables c and d, with values 3 and -1. Then split the variables.

```{r}
#| eval: false
c <- # you should assign the value 3
d <- # you should assign the value -1
```

```{r}
#| code-fold: true
#| eval: false
c <- 3
d <- -1
c / d # no saved
div <- c / d # saved
```

### [**Exercise 4**]{.hl-yellow}

📝 Assign a positive value to `x` and calculate its square root; assign another negative `y` and calculate its absolute value with the `abs()` function.

```{r}
#| code-fold: true
#| eval: false
x <- 5
sqrt(x)

y <- -2
abs(y)
```

### [**Exercise 5**]{.hl-yellow}

📝 Using the variable `x` already defined, complete/modify the code below to store in a new variable `z` the result stored in `x` minus 5.

```{r}
#| eval: false
z <- ? - ? # complete the code
z
```

```{r}
#| code-fold: true
#| eval: false
z <- x - 5
z
```
:::

::: callout-note
## Note that...

Functions as`sqrt()`, `abs()` or `max()` are what we call [**functions**]{.hl-purple}: lines of code that we have "encapsulated" under a name, and given some input arguments, execute the commands (a kind of shortcut).

:::

---

##  Be organized: projects

In the same way that on the computer we usually work [**ordered by folders**]{.hl-yellow}, in `RStudio` we can do the same to work in [**efficient way by creating projects**]{.hl-yellow}.

. . .

::: columns
::: {.column width="60%"}
A [**project will be a "folder "**]{.hl-yellow} inside `RStudio`, so our working directory will automatically be the project folder itself (you can switch from one project to another with the top right menu).

We can create one in a new folder or in an existing folder.
:::

::: {.column width="40%"}
![](img/rstudio_proyectos.png){width="370"}
:::
:::

---

## From the VALUE to the DATABASE

What [**data type**]{.hl-yellow} can we have in each cell of a **database**?

![](img/celdas.jpg){fig-align="middle"}

::: incremental
- [**Cell (single value)**]{.hl-yellow}: single data of a specific type.
- [**Variable**]{.hl-yellow}: **concatenation** of values of the same type ([**vectors**]{.hl-purple}).
- [**Matrix**]{.hl-yellow}: concatenation of variables of **same type and length**.
- [**Data table**]{.hl-yellow}: concatenation of variables of [**different type but equal length**]{.hl-purple}.
- [**List**]{.hl-yellow}: concatenation of variables of [**different type and different length**]{.hl-purple}
:::

---

## Type of (single) data

Are there [**variables beyond numbers**]{.hl-yellow}?


. . .

Let us think, for example, of a person's stored data:

::: {.fragment .fade-up}
- The age or weight will be a [**numeric variable**]{.hl-yellow}.

```{r}
age <- 33
```
:::

::: {.fragment .fade-up}
- Its name will be a string of [**text (string or char)**]{.hl-yellow}.

```{r}
name <- "javi"
```
:::

::: {.fragment .fade-up}
- To the question "Are you single?", the answer will be what we call as a [**logical variable**]{.hl-yellow} (`TRUE` if you are single or `FALSE` otherwise).

```{r}
single <- TRUE
```
:::

::: {.fragment .fade-up}
-   Your date of birth will be just that, a [**date**]{.hl-yellow}.

:::

---

## Numeric variables

The simplest data (we have already used it) will be the [**numeric variables**]{.hl-yellow}

```{r}
#| eval: false
a <- 5
b <- 2
a + b
```

```{r}
#| echo: false
#| include: false
a <- 5
b <- 2
a + b
```

. . .

To know the type of a variable we have the function `class()`.

```{r}
class(a)
```

. . .

With numeric variables we can perform the [**arithmetic operations**]{.hl-yellow} of a calculator: addition (`+`), square root (`sqrt()`), square (`^2`), etc.

```{r}
a^2
abs(a)
```

---

## String variables

Let us imagine that, in addition to the age of a person, we want to store his/her name: now the variable will be of type `character`.

```{r}
name <- "Javier"
class(name)
```

. . .

[**Strings variables**]{.hl-yellow} are a type with which we obviously [**cannot perform arithmetic operations**]{.hl-red} (other operations such as pasting or locating patterns can be performed).

```{r}
#| error: true
name + 1
```

. . .

::: callout-warning
## Note that...

String variables are [**ALWAYS in quotes**]{.hl-orange}: `TRUE` (logical, binary value) is not the same as `"TRUE"` (char or string).
:::

---

## First function: paste

In `R` we denote as [**function**]{.hl-yellow} a piece of [**encapsulated code**]{.hl-yellow} under a name, and which depends on some input [**arguments**]{.hl-yellow}. Our first function will be `paste()`: given two strings, it allows us to paste them together.

```{r}
paste("Javier", "Álvarez")
```

. . .

Note that [**default**]{.hl-yellow} pastes strings with a space, but we can add an [**optional argument**]{.hl-yellow} to tell it the separator (in `sep = ...`).

```{r}
paste("Javier", "Álvarez", sep = "*")
```

---

## First function: paste

::: columns
::: {.column width="50%"}
![](img/paste_help.jpg)
:::

::: {.column width="50%"}
How to know [**what arguments a function needs**]{.hl-yellow}? By typing `? paste` in the console, you will get a [**help**]{.hl-yellow} in the multi-purpose panel.

In this help panel, you will see in its header what arguments the function already has [**default**]{.hl-yellow} assigned to it.
:::
:::

. . .

There is a similar function named as `paste0()` that pastes by default with `sep = ""` (without anything else).

```{r}
paste0("Javier", "Álvarez")
```

---

## First package: glue

A more intuitive way to work with string variables is to use the `{glue}` package: the first thing to do is to "buy the book" (if we have never done it before). After that [**load the package**]{.hl-yellow}

```{r}
#| eval: false
install.packages("glue")
library(glue)
```

```{r}
#| echo: false
library(glue)
```

. . .

This package allows us to use [**variables inside strings**]{.hl-yellow}. For example, "I am ... years old", where the age is stored in a variable.

```{r}
age <- 33
glue("I am {age} years old")
```

. . .

Inside brackets we can also execute operations

```{r}
units <- "days"
glue("I am {age * 365} {units} old")
```

---

## Logical conditions

Another fundamental type will be the [**logical or binary or boolean variables**]{.hl-yellow} (**just two values**):

- `TRUE`: [**true**]{.hl-yellow} stored internally as a 1.
- `FALSE`: [**false**]{.hl-yellow} stored internally as a 0.

```{r}
single <- TRUE # Are you single? --> YES
class(single)
```

. . .

It can take a third value, `NA` or [**missing data**]{.hl-yellow}, the acronym for *not available*.

. . .

::: callout-important
## Important

Logical variables [**NOT string variables**]{.hl-red}: `"TRUE"` is a string, `TRUE` is a logical value.

```{r}
#| error: true
TRUE + 1
"TRUE" + 1
```
:::

---

## Logical conditions

Logical values are usually the result of [**evaluate logical conditions**]{.hl-yellow}. For example, let us imagine we want to check if my name is Javi.

```{r}
name <- "María"
```

. . .

The [**logical operator**]{.hl-yellow} `==` allow us to ask if left equals right.

```{r}
name == "Javi"
```

. . .

With its opposite `!=` we ask if it is different.

```{r}
name != "Javi"
```

. . .

::: callout-note
## Note that...

It is not the same `<-` ([**assignment**]{.hl-yellow}) as `==` (we are [**asking**]{.hl-yellow}, it is a logical comparison).

:::

---

## Logical conditions

In addition to "equal to" versus "different" comparisons, also order comparisons such as `<, <=, > or >=`.

**Is the person less than 32 years old?**

```{r}
age <- 38
age < 32
```

**Age is greater than or equal to 38 years old?**

```{r}
age >= 38
```


---

## Date variables

A very special data type: the [**date type data**]{.hl-yellow}.

```{r}
date_char <- "2021-04-21"
```

. . .

It looks like a simple string but [**represents an instant in time**]{.hl-yellow}. What should happen if [**we add a 1 to a date**]{.hl-purple}?

```{r}
#| error: true
date_char + 1
```

. . .

Dates [**cannot be string variables**]{.hl-red}: we must convert string variables to date with `as_date()` from the `{lubridate}` package.


```{r}
library(lubridate)
date <- as_date("2023-03-28")
date + 1
class(date)
```

---

## Date variables

In this package we have very useful functions for [**handling dates**]{.hl-yellow}:

-   `today()` allowes to directly obtain the [**current date**]{.hl-purple}.

```{r}
today()
```

. . .

-  `now()` allows to obtain [**current datetime**]{.hl-purple}

```{r}
now()
```

. . .

-  `year()`, `month()` or `day()` allows us to [**extract year, month and day**]{.hl-purple} for a given date.

```{r}
date <- today()
year(date)
month(date)
```

---

## Cheatsheets

![](img/lubridate.png)

::: callout-note
## More documentation

You have a pdf summary of the most important packages in the [**corresponding folder on campus**]{.hl-green}. See also <https://posit.co/resources/cheatsheets/>
:::

---

## 💻 Your turn {#tu-turno-1}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Define a variable that stores your age (named as `age`) and another with your name (named as `name`).

```{r}
#| code-fold: true
age <- 33
name <- "Javi"
```

### [**Exercise 2**]{.hl-yellow}

📝 Define another variable named as `siblings` that answers the question "do you have siblings?" and another one with the date of your birth (named as `birth_date`).

```{r}
#| code-fold: true
siblings <- TRUE

library(lubridate)
birth_date <- as_date("1989-09-10")
```

### [**Exercise 3**]{.hl-yellow}

📝 Define another variable with your last names (named as `surnames`) and use `glue()` to have a single variable `full_name` (separating first and last name by a comma).

```{r}
#| code-fold: true
#| eval: false
surnames <- "Álvarez Liébana"
glue("{name}, {surnames}")
```

### [**Exercise 4**]{.hl-yellow}

📝 Compute the days that have passed from the date of your birth until today (with the date of birth defined in exercise 2).

```{r}
#| code-fold: true
#| eval: false
today() - birth_date
```
:::

---

## Vectors: concatenate

Working with data usually implies having [**columns that represent variables**]{.hl-yellow}: we will call [**vectors**]{.hl-yellow} a [**concatenation**]{.hl-purple} of cells (values) of the [**same type**]{.hl-purple}.

. . .

The simplest way is using the `c()` command (c, **concatenate**), and just introduce its **elements between parentheses, and separated by commas**.

```{r}
age <- c(33, 27, 60, 61)
age
```

. . .

::: callout-tip
A single number `x <- 1` (or `x <- c(1)`) is actually a vector of length one.
:::

---

## Vectors: concatenate

::: columns
::: {.column width="40%"}
![](img/edades_environment.jpg)
:::

::: {.column width="60%"}
As you can see, in the `environment` area we have now a **collection of elements** saved

```{r}
age
```
:::
:::

. . .

The [**length of a vector**]{.hl-yellow} can be computed with `length()`.

```{r}
length(age)
```

. . .

We can also  [**concatenate vectors themselves**]{.hl-yellow}

```{r}
c(age, age, 8)
```

---

## Numerical sequences

Many times we will want to create [**numeric sequences**]{.hl-yellow} (for example, the days of the month). The `seq(start, end)` command allows us to create a **sequence** from a start element to an end element, [**advance one at a time**]{.hl-purple}.

```{r}
seq(1, 31)
```

. . .

The command `1:n` returns the same as `seq(1, n)` (if the initial element is greater than the final one, it will understand that the sequence is [**decreasing**]{.hl-purple}).

```{r}
1:5
7:-3
```

---

## Numerical sequences

We can also define [**other type of discretization step**]{.hl-yellow} between consecutives

```{r}
seq(1, 7, by = 0.5) # from 1 to 7 by step = 0.5
```

. . .

In other cases we will be interested in defining a [**sequence with a specific length**]{.hl-yellow}

```{r}
seq(1, 50, l = 7) # length 7
```

. . .

We may even want to generate a vector of [**n repeated elements**]{.hl-yellow}.

```{r}
rep(0, 7)
```

---

## Vectors: characters

A vector is a **concatenation** of [**same type**]{.hl-yellow} elements, but they do not necessarily have to be numerical types. Let us create an example sentence.

```{r}
sentence <- "I am Javi"
sentence
length(sentence)
```

. . .

In the previous case it was not a vector, it was a single text element. To create a vector we must use `c()` again and separate elements with commas.

```{r}
vector <- c("I", "am", "Javi")
vector
length(vector)
```

---

## Vectors

What will happen if we [**concatenate elements of different type**]{.hl-yellow}?

. . .

```{r}
c(1, 2, "javi", "3", TRUE)
```

Notice that since they are all of the same type, what `R` does is [**convert**]{.hl-yellow} everything to character,  [**violating data integrity**]{.hl-red}

. . .

```{r}
c(3, 4, TRUE, FALSE)
```

It is important to understand that the logical values are actually [**stored internally as 0/1**]{.hl-yellow}

---

## Operating with vectors

With numeric vectors we can do the same [**arithmetic operations**]{.hl-yellow} as with numbers → a [**number is a vector**]{.hl-purple} (of length one).

. . .

What will happen if we [**add or subtract a value**]{.hl-yellow} to a vector?

. . .

```{r}
x <- c(1, 3, 5, 7)
x + 1
x * 2
```

::: callout-warning
## Be careful

Unless we indicate otherwise, in `R` operations with vectors are always [**element to element**]{.hl-orange}
:::

---

## Operating with vectors

Vectors can also interact with each other, so we can define, for example, [**sums of vectors**]{.hl-yellow} (element by element)

```{r}
x <- c(2, 4, 6)
y <- c(1, 3, 5)
x + y
```

. . .

Since the operation (e.g., a sum) is performed element by element, what will happen if [**let's add two vectors of different length**]{.hl-yellow}?

. . .

```{r}
z <- c(1, 3, 5, 7)
x + z
```

What it does is [**recycle elements**]{.hl-yellow}: if you have a vector of 4 elements and we add another one of 3 elements, it will recycle from the vector with smaller length.

---

## Operating with vectors

A very common operation is to [**ask data**]{.hl-yellow} by using [**logical conditions**]{.hl-purple}. For example, if we define a vector of temperatures....

[**What days was it less than 22 degrees**]{.hl-yellow}

```{r}
x <- c(15, 20, 31, 27, 15, 29)
```

. . .

```{r}
x < 22
```

It will return a [**logical vector**]{.hl-yellow}, depending on whether **each element** fulfills or not the requested condition (of **equal length** to the requested vector).

. . .

If we had a [**missing data**]{.hl-yellow} (e.g., due to device error that day), the evaluated condition would also be `NA`.

```{r}
y <- c(15, 20, NA, 31, 27, 7, 29, 10)
y < 22
```

---

## Operating with vectors

Logical [**conditions can be combined**]{.hl-yellow} in two ways:

- [**Intersection**]{.hl-yellow}: [**all**]{.hl-purple} concatenated conditions must be checked ([**conjunction and**]{.hl-purple} with `&`) to return a `TRUE`.

```{r}
x < 30 & x > 15
```

-    [**Union**]{.hl-yellow}: it is sufficient that [**at least one**]{.hl-purple} is fulfilled ([**conjunction or**]{.hl-purple} with `|`).

```{r}
x < 30 | x > 15
```

. . .

`any()` and `all()` allow us to check that [**all (or any) elements**]{.hl-yellow} meet the following criteria

```{r}
any(x < 30)
all(x < 30)
```

---

## Operating with vectors

We can also use [**statistical operations**]{.hl-yellow} such as `sum()` which, given a vector, returns the sum of all its elements.

```{r}
x <- c(1, -2, 3, -1)
sum(x)
```

[**What happens when a single value is missing?**]{.hl-yellow}

. . .

```{r}
x <- c(1, -2, 3, NA, -1)
sum(x)
```

By default, if we have a missing data, the [**operation will also be missing**]{.hl-yellow}. In order to [**remove that data**]{.hl-purple}, we use an optional argument `na.rm = TRUE`.

```{r}
sum(x, na.rm = TRUE)
```

---

## Operating with vectors

As we have mentioned, logical values are stored internally as 0 and 1, so we can use them in arithmetic operations.


For example, if we want to [**find the number of elements that fulfill a condition**]{.hl-yellow} (for example, "less than 3"), those that do will be assigned a 1 (`TRUE`) and those that don't a 0 (`FALSE`), so we only need to add this logical vector to obtain the number of elements that fulfill a condition.

```{r}
x <- c(2, 4, 6)
sum(x < 3)
```

---

## Operating with vectors

Other common operations are [**average**]{.hl-yellow}, [**median**]{.hl-yellow}, [**percentiles**]{.hl-yellow}, etc.


- [**Average (mean)**]{.hl-yellow}: centrality measure that consists of adding all the elements and dividing by the number of elements added. The best known but the [**least robust**]{.hl-red}: given a set, if outliers (very large or very small values) are introduced, the mean is strongly perturbed.


```{r}
x <- c(165, 170, 181, 191, 150, 155, 167, NA, 173, 177)
mean(x, na.rm = TRUE)
```

---

## Operating with vectors

Other common operations are [**average**]{.hl-yellow}, [**median**]{.hl-yellow}, [**percentiles**]{.hl-yellow}, etc.


-   [**Median**]{.hl-yellow}: measure of centrality that consists of ordering the elements and keeping the one that occupies the middle.


```{r}
x <- c(165, 170, 181, 191, 150, 155, 167, 173, 177)
median(x)
```

. . .

-   [**Percentiles**]{.hl-yellow}: measures of location (they divide the data into equal parts).

```{r}
quantile(x) # por defecto percentiles 0-25-50-75-100
quantile(x, probs = c(0.1, 0.4, 0.9))
```

---

## Operating with vectors

Another very common operation is to [**access elements**]{.hl-yellow} of it. The simplest way is to use the `[i]` operator (access the i-th element).

```{r}
age <- c(20, 30, 33, NA, 61) 
age[3] # third position
```

. . .


Since a number is just a vector of length one, this operation can also be applied using a [**vector of indexes to select**]{.hl-yellow}

```{r}
y <- c("Hi", "how", "are", "you", "?")
y[c(1:2, 4)] # first, second and fourth elemento
```

::: callout-tip
To access the last one, without worrying about which one, we can pass as index the length `x[length(x)]`.

:::

---

## Operating with vectors

Other times we will not want to select but [**delete some elements**]{.hl-yellow}. We will have to repeat the same operation but with the sign `-` in front: the operator `[-i]` does not select the i-th element of the vector but discards it.

```{r}
y
y[-2]
```


. . .

Many times we will want to [**select or eliminate based on logical conditions**]{.hl-yellow}, depending on the values, so we will pass as index the condition itself (remember, `x < 2` returns a logical vector).

```{r}
age <- c(15, 21, 30, 17, 45)
names <- c("javi", "maría", "laura", "carla", "luis")
names[age < 18] 
```

---

## Operating with vectors

Finally, a common action is to [**sort values**]{.hl-yellow}:

-   `sort()`: returns the [**sorted vector**]{.hl-yellow}. By default from smallest to largest but with `decreasing = TRUE` we can change it.

```{r}
age <- c(81, 7, 25, 41, 65, 20, 33, 23, 77)
sort(age)
sort(age, decreasing = TRUE)
```

. . .

-   `order()`: returns the [**index vector**]{.hl-yellow} that we would have to use to have the sorted vector.

```{r}
order(x)
x[order(x)]
```

---

## 💻 Your turn {#tu-turno-1a}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Define the vector `x` as the concatenation of the first 5 odd numbers, and calculate their sum.

```{r}
#| code-fold: true
#| eval: false
# Two ways
x <- c(1, 3, 5, 7, 9)
x <- seq(1, 9, by = 2)

sum(x)
```

### [**Exercise 2**]{.hl-yellow}

📝 Get the elements of `x` greater than 4. Calculate the number of elements of `x` greater than 4.

```{r}
#| code-fold: true
#| eval: false
x[x > 4]
sum(x > 4)
```

### [**Exercise 3**]{.hl-yellow}

📝 Calculate the vector `1/x` and obtain the ordered version (from smallest to largest).

```{r}
#| code-fold: true
#| eval: false
z <- 1/x
sort(z)
z[order(z)]
```

### [**Exercise 4**]{.hl-yellow}

📝 Find the maximum and minimum of vector `x`.

```{r}
#| code-fold: true
#| eval: false
min(x)
max(x)
```

### [**Exercise 5**]{.hl-yellow}

📝 Find of the vector `x` the elements greater (strictly) than 1 and less (strictly) than 7. Find a way to find out if all the elements are positive or not.

```{r}
#| code-fold: true
#| eval: false
x[x > 1 & x < 7]
all(x > 0)
```

### [**Exercise 6**]{.hl-yellow}

📝 Given the vector `x <- c(1, -5, 8, NA, 10, -3, 9)`, extract the elements that occupy the places 1, 2, 5, 6. Removes from the vector the second element. After removing it, compute its sum and mean

```{r}
#| code-fold: true
#| eval: false
x <- c(1, -5, 8, NA, 10, -3, 9)
x[c(1, 2, 5, 6)]
y <- x[-2]
sum(y, na.rm = TRUE)
mean(y, na.rm = TRUE)
```
:::

---

## 🐣 Case study {#caso-práctico-1}

In the `{datasets}` package we have several datasets, and one of them is named as `airquality`. I have extracted below 3 variables from this dataset

```{r}
temperature <- airquality$Temp
month <- airquality$Month
day <- airquality$Day
```

1. What [**represents the data**]{.hl-yellow}? How to find out?

. . .

2. How many [**records do we have for May**]{.hl-yellow}? What about April? Construct a new `date` variable with the [**date**]{.hl-yellow} of each record (combining year, month and day).

. . .

3. Create a new variable `temp_celsius` with the [**temperature in ºC**]{.hl-yellow} (units of the original variable are in Fahrenheit)

. . .

4. What was the [**average temperature**]{.hl-yellow} for the month of August? Extract the days when the [**temperature exceeded 30 degrees**]{.hl-yellow} and determine the number of days when it did.


# Lesson 2: first databases {#clase-2}

[**First databases: tibbles as standard type for databases. R base vs tidyverse. Pipe operator. Principles of tidy data: tidy vs messy data. Pivoting datasets**]{style="color:#444442;"}

---


## First attempt: matrices

In data science we usually have [**several variables**]{.hl-yellow} for each individual: we need a "table" to collect them. The most immediate option is [**matrices**]{.hl-yellow}: a concatenation of variables of [**same type and equal length**]{.hl-purple}.

. . .

Let us imagine that we have heights and weights of 4 people. How to [**create a dataset with those variables**]{.hl-yellow}?


-   Function `cbind()` allow us to [**concatenate vectors by columns**]{.hl-yellow}

```{r}
heights <- c(150, 160, 170, 180)
weights <- c(63, 70, 85, 95)
data_matrix <- cbind(heights, weights)
data_matrix
```

---

## First attempt: matrices

- We can also [**define a matrix by rows**]{.hl-yellow} with the `rbind()` function (although it is recommended to have each variable in column and individuals in row).

```{r}
rbind(heights, weights)
```

- We can [**view the matrix**]{.hl-yellow} (in a tabular way) using the function `View()`.

. . .

- We can [**check dimensions**]{.hl-yellow} with `dim()`, `nrow()` and `ncol()` (data is now tabulated).

```{r}
dim(data_matrix)
nrow(data_matrix)
```

---

## First attempt: matrices

- We can also [**transpose a matrix**]{.hl-yellow} with `t()`.

```{r}
t(data_matrix)
```

. . .

- Since we now have two dimensions, to [**access elements**]{.hl-yellow} we must provide the index of the row and column inside of brackets (if they are free, it implies all of that dimension)

```{r}
data_matrix[2, 1]
data_matrix[, 2]
```

---

## First attempt: matrices

- We can also define a [**matrix from a numeric vector**]{.hl-yellow}, reorganizing the values in the form of a matrix (knowing that the elements are **placed by columns**).

```{r}
z <- matrix(1:15, ncol = 5) 
z
```

. . .

With matrices it is the same as with vectors: when we apply an [**arithmetic operation, we do it element by element**]{.hl-yellow}

```{r}
z/5
```

---

## First attempt: matrices

We can also apply [**apply functions by columns/rows**]{.hl-yellow} (avoiding loops) with `apply()`, taking as **input arguments**

- a matrix
- the sense (`MARGIN = 1` by rows, `MARGIN = 2` by columns)
- a function to be applied.

. . .

```{r}
# Mean by columns (MARGIN = 2)
apply(data_matrix, MARGIN = 2, FUN = "mean")

# (Quasi)var (var) by columns (MARGIN = 2)
apply(data_matrix, MARGIN = 2, FUN = "var")
```

. . .

[**We won't go deeper**]{.hl-red} any further since our goal is to have variables of the same length but [**different types**]{.hl-yellow} (but know they exist).

---

## 💻 Your turn (matrices) {#tu-turno-matrices}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Modify the code below to define an `x` matrix of ones with 3 rows and 7 columns.

```{r}
#| eval: false
x <- matrix(0, nrow = 2, ncol = 3)
x
```

```{r}
#| code-fold: true
#| eval: false
x <- matrix(1, nrow = 3, ncol = 7)
x
```

### [**Exercise 2**]{.hl-yellow}

📝 Add a 1 to each number in the matrix above, and divide the result by 5. After that, calculate its transpose and obtain its dimensions

```{r}
#| code-fold: true
#| eval: false
new_matrix <- (x + 1)/5
t(new_matrix)
dim(new_matrix)
```

### [**Exercise 3**]{.hl-yellow}

📝 Define matrix `x <- matrix(1:12, nrow = 4)`. Get the first row, the third column, and the element (4, 1).

```{r}
#| code-fold: true
#| eval: false
x <- matrix(1:12, nrow = 4)
x[1, ] # first row
x[, 3] # third column
x[4, 1] # element (4, 1)
```

### [**Exercise 4**]{.hl-yellow}

📝 With the above matrix defined as `x <- matrix(1:12, nrow = 4)`, calculate the mean of all elements, the mean of each row and the mean of each column. Calculate the sum of each row and each column.

```{r}
#| code-fold: true
#| eval: false
x <- matrix(1:12, nrow = 4)
mean(x) # mean (of all elements)
apply(x, MARGIN = 1, FUN = "mean") # mean by rows
apply(x, MARGIN = 2, FUN = "mean") # mean by columns
apply(x, MARGIN = 1, FUN = "sum") # sum by rows
apply(x, MARGIN = 2, FUN = "sum") # sum by columns

```
:::

---

## Second attempt: data.frame

Matrices have the same problem as vectors: if we collect data of different types together, [**data integrity is compromised**]{.hl-red} as it converts them into.

```{r}
#| code-line-numbers: "4-5"
ages <- c(14, 24, NA)
single <- c(TRUE, NA, FALSE)
names <- c("javi", "laura", "lucía")
matrix <- cbind(ages, single, names)
matrix
```

. . .

Since we are no longer numbers, we cannot perform arithmetic operations.

```{r}
#| error: true
matrix + 1
```

---

## Second attempt: data.frame

In order to work with [**variables of different type**]{.hl-yellow} we have what is known as [**data.frame**]{.hl-yellow}: concatenation of variables of equal length but may be of [**different type**]{.hl-purple}.

```{r}
#| code-line-numbers: "1"
table <- data.frame(ages, single, names)
class(table)
table
```

---

## Second attempt: data.frame

Since a `data.frame` is already a `database` the variables are not mere mathematical vectors: [**they have a meaning**]{.hl-yellow} and we can (must) [**name them**]{.hl-purple}.

```{r}
library(lubridate)
table <- data.frame("ags" = ages, "single" = single, "name" = names,
             "b_date" = as_date(c("1989-09-10", "1992-04-01", "1980-11-27")))
table
```

---

## Second attempt: data.frame

[**We have our first dataset!**]{.hl-yellow} You can view it by typing its name in the console or with `View(table)`.

![](img/view_tabla.jpg)

---

## Second attempt: data.frame

If we want to access its elements, we can, as in matrices (although it is not recommended): now [**we have two indexes**]{.hl-yellow} (rows and columns, leaving free the one we don't use)

```{r}
table[2, ]  # second row (all variables)
table[, 3]  # third column (all individuals)
table[2, 1]  # first variable for the second individual
```

. . .

::: columns
::: {.column width="25%"}
![](img/menu_data_frame.jpg)
:::

::: {.column width="75%"}
It also has advantages of a [**database**]{.hl-yellow} : we can [**access variables by name**]{.hl-purple} (**recommendable** since variables can change position), putting the name of the table followed by the symbol `$` (with the **tab**, a menu of columns to choose from will appear).
:::
:::

---

## Second attempt: data.frame

- `names()`: show us the names of the variables.

```{r}
names(table)
```

. . .

- `dim()`: show us the dimensions (see also `nrow()` and `ncol()`)

```{r}
dim(table)
```

. . .

-  We can access to variables by name

```{r}
table[c(1, 3), "name"]
```

---

## Second attempt: data.frame

If we have one already created and we want to [**add a column**]{.hl-yellow} it is as simple as using the `data.frame()` function we have already seen to concatenate the column. Let's add for example a new variable, the number of siblings of each individual.

```{r}
# Add new column
siblings <- c(0, 2, 3)
table <- data.frame(table, "n_sib" = siblings)
table
```

---

## Final attempt: tibble

Tables in `data.frame` format have some [**limitations**]{.hl-red}

The main one is that [**does not allow recursion**]{.hl-red}: imagine we define a database with heights and weights, and we want a third variable with BMI.

```{r}
#| error: true
data.frame("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70),
           "BMI" = weight / (height^2))
```

. . .

From now on we will use the `tibble` format (an [**enhanced data.frame**]{.hl-yellow}).

```{r}
library(tibble)
tibble("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70),
       "BMI" = weight / (height^2))
```

---

## Final attempt: tibble

```{r}
table <- tibble("height" = c(1.7, 1.8, 1.6), "weight" = c(80, 75, 70),
                "BMI" = weight / (height^2))
table
```

Tables in `tibble` format will allow a [**more agile, efficient and coherent**]{.hl-yellow} data management, with 4 main advantages:

. . .

- [**Metainfo**]{.hl-yellow}: if you look at the header, it automatically tells us the number of rows and columns, and the type of each variable.

. . .

- [**Recursivity**]{.hl-yellow}: allows you to define the variables sequentially (as we have seen).

---

## Final attempt: tibble

- [**Consistency**]{.hl-yellow}: if you access a column that does not exist, a warning message is issued.

```{r}
#| warning: true
table$invent
```

. . .

- [**By rows**]{.hl-yellow}: create by rows (copy and paste from a table) with `tribble()`.

```{r}
tribble(~colA, ~colB,
        "a",   1,
        "b",   2)
```

. . .

::: callout-tip
## Tip
The `{datapasta}` package allows us to [**copy and paste**]{.hl-green} tables from web pages and simple documents.
:::


---

## 💻 Your turn (tibble) {#tu-turno-tibble}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Load from the `{datasets}` package the `airquality` dataset (New York air quality variables from May through September 1973). Is the airquality dataset of type tibble? If not, convert it to tibble (look in the package documentation at <https://tibble.tidyverse.org/index.html>).

```{r}
#| code-fold: true
#| eval: false
library(tibble)
class(datasets::airquality)
airquality_tb <- as_tibble(datasets::airquality)
```

### [**Exercise 2**]{.hl-yellow}

📝 Once converted into `tibble` get the name of the variables and the dimensions of the data set. How many variables are there? How many days have been measured?

```{r}
#| code-fold: true
#| eval: false
names(airquality_tb)
ncol(airquality_tb)
nrow(airquality_tb)
```

### [**Exercise 3**]{.hl-yellow}

📝 Filters only data for the month of August.

```{r}
#| code-fold: true
#| eval: false
airquality_tb[airquality_tb$Month == 8, ]
```

### [**Exercise 4**]{.hl-yellow}

📝 Select those data that are not from July or August.

```{r}
#| code-fold: true
#| eval: false
airquality_tb[!(airquality_tb$Month %in% c(7, 8)), ]
```

### [**Exercise 5**]{.hl-yellow}

📝 Modify the following code to keep only the ozone and temperature variables.

```{r}
#| code-fold: true
#| eval: false
airquality_tb[, c("Ozone", "Temp")]
```

### [**Exercise 6**]{.hl-yellow}

📝 Select the temperature and wind data for August. Translate the name of the columns of the filtered set to your motherlanguage.

```{r}
#| code-fold: true
#| eval: false
airquality_tb[airquality_tb$Month == 8, c("Temp", "Wind")]
names(airquality_tb) <- c("ozono", "rad_solar", "viento", "temp", "mes", "dia") 
```
:::

---

## Summary

- Each [**cell can be of a different type**]{.hl-yellow}: numbers, text, dates, logical values, etc.

. . .

- A [**vector is a concatenation of cells**]{.hl-yellow} (columns of our tables) --> In `R` by default the operations are done [**element by element**]{.hl-yellow}

. . .

- A [**matrix**]{.hl-yellow} allows us to concatenate [**variables of the SAME type and SAME length**]{.hl-yellow} --> two-dimensional object (two indices)

. . .

- A [**data.frame**]{.hl-yellow} allows us to concatenate [**variables of DIFFERENT type and SAME length**]{.hl-yellow} --> we will use [**tibble**]{.hl-yellow} as an enhanced database option.

---

## 🐣 Case study {#caso-práctico-2}

From the `{Biostatistics}` package we will use the `pinniped` data set.

```{r}
#| eval: false
Biostatistics::pinniped
```

1. What [**data type**]{.hl-yellow} does the data represent? What [**data type**]{.hl-yellow} is it? If not, convert the database to a `tibble` (rename with `pinniped_tb`).

. . .

2. How many records are there, and variables, what type is each one?

. . .

3. Incorporate an [**extra variable named phoca**]{.hl-yellow} that is of logical type and check whether a species is of category `Phoca` or not.

. . .

4. Which sex is [**weighted more by brain**]{.hl-yellow}: females or males? Who is [**weighted more by body**]{.hl-yellow}: monogamous or polygamous?

. . .

5. Add a new variable representing the [**difference in brain weight between males and females**]{.hl-yellow} (males - females) for each species.


---

## R base vs Tidyverse

If you know any other programming language, you will be surprised that we have not yet talked about common concepts such as

- [**For loops**]{.hl-yellow}: repeat a code a fixed number of iterations.

- [**while loops**]{.hl-yellow}: repeat a code until a condition is verified.

- [**if-else structures**]{.hl-yellow}: control flow structures to decide where the code walks depending on the value of variables.

. . .

And although knowing these structures can be interesting at some point, in [**most of the times we will be able to avoid them**]{.hl-red} (specially loops).

---

## What about tidyverse?

::: columns
::: {.column width="50%"}
![](img/tidyverrse_universe.jpg)
:::

::: {.column width="50%"}
![](img/flow_tidyverse.jpg)
:::
:::

`{tidyverse}` is an [**"universe" of packages**]{.hl-yellow} to ensure an efficient, coherent and lexicographically simple to understand workflow based on the idea that [**our data is clean and tidy**]{.hl-purple}

---

## What about tidyverse?

::: columns
::: {.column width="45%"}
![](img/tidyverrse_universe.jpg)
:::

::: {.column width="55%"}
- `{tibble}`: optimizing data.frame
- `{tidyr}`: data cleaning
- `{readr}`: loading rectangular data (.csv)
- `{dplyr}`: grammar for debugging
- `{stringr}`: text handling
- `{ggplot2}`: data visualization
- `{tidymodels}`: modeling/prediction
:::
:::

We also have the `{purrr}` packages for list management, `{forcast}` for qualitative variables, `{lubridate}` for dates, `{readxl}` for importing .xls and .xlsx files, `{rvest}` for web scraping and `{rmarkdown}` for reporting results.

---

## What about tidyverse?

::: columns
::: {.column width="45%"}
![](img/tidyverrse_universe.jpg)
:::

::: {.column width="55%"}
-   `{tibble}`: [**optimizing data.frame**]{.hl-yellow}
-   `{tidyr}`: [**data cleaning**]{.hl-yellow}
- `{readr}`: loading rectangular data (.csv)
- `{dplyr}`: grammar for debugging
- `{stringr}`: text handling
- `{ggplot2}`: data visualization
- `{tidymodels}`: modeling/prediction
:::
:::

We also have the `{purrr}` packages for list management, `{forcast}` for qualitative variables, `{lubridate}` for dates, `{readxl}` for importing .xls and .xlsx files, `{rvest}` for web scraping and `{rmarkdown}` for reporting results.

---

## Idea: Tidy Data

> Tidy datasets are all alike, but every messy dataset is messy in its own way (Hadley Wickham, Chief Scientist en RStudio)

::: {style="font-size:120px; text-align: center; color:#F8DF58;"}
<b>TIDY</b><b>[VERSE</b>]{style="color:#CAB0EE;"}
:::

The [**universe**]{.hl-purple} of `{tidyverse}` packages is based on the idea introduced by **Hadley Wickham** (the God I pray to) of [**standardize**]{.hl-yellow} formatting data to

::: incremental
- [**systematize**]{.hl-green} debugging
- make it [**simpler**]{.hl-green} to manipulate.
- [**readable**]{.hl-green} code.
:::

---

## Tidy data: rules

The first thing will therefore be to understand what the [**tidydata sets**]{.hl-yellow} are, since the whole `{tidyverse}` is based on the data being standardized.

::: columns
::: {.column width="50%"}
::: {.fragment .fade-in}
1. Each [**variable**]{.hl-yellow} in a [**single column**]{.hl-purple}
:::

::: {.fragment .fade-in}
2.  Each [**individual**]{.hl-yellow} in a [**different row**]{.hl-purple}
:::

::: {.fragment .fade-in}
3.  Each [**cell**]{.hl-yellow} with a [**single value**]{.hl-purple}
:::

::: {.fragment .fade-in}
4.  Each [**dataset**]{.hl-yellow} in a [**tibble**]{.hl-purple}
:::

::: {.fragment .fade-in}
5.  If we want to cross [**multiple tables**]{.hl-yellow} we must have a [**common (key) column**]{.hl-purple}
:::
:::

::: {.column width="50%"}
![](img/tidy_def.jpg){width="160%"}
:::
:::

---

## Pipe operator

In `{tidyverse}` the [**pipe operator**]{.hl-yellow}, defined as `|>` ([**ctrl+shift+M**]{.hl-purple}), will be key: it will be a [**pipe that traverses the data**]{.hl-yellow} and transforms it.

. . .

::: columns
::: {.column width="50%"}
In R base, if we want to apply three functions `first()`, `second()` and `third()` in order, it would be

```{r}
#| eval: false
third(second(first(data)))
```
:::

::: {.column width="50%"}
In `{tidyverse}` we can [**read from left to right**]{.hl-yellow} and separate the data from the actions

```{r}
#| eval: false
data |> first() |> second() |> third()
```
:::
:::


. . .

::: callout-caution
## Note that...

Since version 4.1.0 of `R` we have `|>`, a **native** pipe available [**outside tidyverse**]{.hl-purple}, replacing the [**old pipe**]{.hl-red} `%>%` which depended on the `{magrittr}` package (quite problematic).
:::

---

## Pipe operator

The main advantage is that the [**code is very readable (almost literal)**]{.hl-yellow} and you can do large operations on the data with very little code.

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
data |>
  tidy(...) |>
  filter(...) |>
  select(...) |>
  arrange(...) |>
  modify(...) |>
  rename(...) |>
  group(...) |>
  count(...) |>
  summary(...) |>
  plot(...)
```
:::

::: {.column width="50%"}
<center><img src="img/logo_pipe.png" width="360px"/></center>
:::
:::

---

## Messy data

But what does the [**non-tidy data**]{.hl-yellow} look like? Let's load the `table4a` table from the `{tidyr}` package (we already have it loaded from the tidyverse environment).


```{r}
library(tidyr)
table4a
```


[**What could be wrong?**]{.hl-red}

---

## Pivoting: pivot_longer()

::: columns
::: {.column width="40%"}
```{r}
table4a
```
:::

::: {.column width="60%"}
❎ Each [**row represents two observations**]{.hl-red} (1999 and 2000) → columns `1999` and `2000` should actually themselves be [**values of a variable**]{.hl-yellow} and not column names.
:::
:::

. . .

We will include a [**new column**]{.hl-yellow} that stores the year and another one that stores the value of the variable of interest in each of those years. And we will do it with the `pivot_longer()` function: [**pivot the table**]{.hl-yellow} to long format

```{r}
table4a |> 
  pivot_longer(cols = c("1999", "2000"), names_to = "year", values_to = "cases")
```

---

## Pivoting: pivot_longer()

::: columns
::: {.column width="50%"}
```{r}
table4a |> 
  pivot_longer(cols = c("1999", "2000"),
               names_to = "year",
               values_to = "cases")
```
:::

::: {.column width="50%"}
![](img/table4a.jpg)
:::
:::


- `cols`: [**name of the variables to be pivoted**]{.hl-yellow}
- `names_to`: name of the new variable to which we send the [**header**]{.hl-yellow} of the table (the names).
- `values_to`: name of the new variable to which we are going to send the [**data**]{.hl-yellow}.

---

## Messy data

Let us see another example in `table2`


```{r}
table2
```


[**What could be wrong?**]{.hl-red}

---

## Pivoting: pivot_wider()

::: columns
::: {.column width="60%"}
```{r}
#| echo: false
table2
```
:::

::: {.column width="40%"}
❎ Each [**observation is divided into two rows**]{.hl-red} → the [**records with the same year should be the same**]{.hl-yellow}
:::
:::

. . .

We will do will be the opposite: with `pivot_wider()` [**we will widen the table**]{.hl-yellow}

```{r}
table2 |>  pivot_wider(names_from = type, values_from = count)
```

---

## Messy data

Let us see another example in `table3`


```{r}
table3
```


[**What could be wrong?**]{.hl-red}

---

## separate()

::: columns
::: {.column width="60%"}
```{r}
table3
```
:::

::: {.column width="40%"}
❎ Each [**cell contains several values**]{.hl-red}
:::
:::

. . .

What we will do is make use of the `separate()` function to send [**separate each value**]{.hl-yellow} to a different column.

```{r}
table3 |> separate(rate, into = c("cases", "pop"))
```

---

## separate()

```{r}
table3 |> separate(rate, into = c("cases", "pop"))
```

Notice that the data, although it has separated them, [**kept them as text**]{.hl-red} when in fact they should be numeric variables. For this we can add the optional argument `convert = TRUE`.
. . .

```{r}
table3 |> separate(rate, into = c("cases", "pop"), convert = TRUE)
```

---

## Messy data

Let us see the last example in `table5`


```{r}
table5
```


[**What could be wrong?**]{.hl-red}

---

## unite()

::: columns
::: {.column width="50%"}
```{r}
table5
```
:::

::: {.column width="50%"}
❎ We have [**same values divided into two columns**]{.hl-red}
:::
:::

. . .

We will use `unite()` to [**unite the values**]{.hl-yellow} of century and year in the same column

```{r}
table5 |> unite(col = year_whole, century, year, sep = "")
```

---

## 💻 Your turn {#tu-turno-2}


[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Take a look at table `table4b` in package `{tidyr}`. Is it tidydata? If not, what is wrong, how to convert it to tidy data in case it is not already?

```{r}
#| code-fold: true
#| eval: false
table4b |>
  pivot_longer(cols = "1999":"2000", names_to = "year",
               values_to = "cases")
```

### [**Exercise 2**]{.hl-yellow}

📝 Take a look at table `relig_income` in package `{tidyr}`. Is it tidydata? If not, what is wrong, how to convert it to tidy data in case it is not already?

```{r}
#| code-fold: true
#| eval: false
relig_income |>
  pivot_longer(cols = "<$10k":"Don't know/refused",
               names_to = "income",
               values_to = "people")
```

### [**Exercise 3**]{.hl-yellow}

📝 Take a look at table `billboard` in package `{tidyr}`. Is it tidydata? If not, what is wrong, how to convert it to tidy data in case it is not already?

```{r}
#| code-fold: true
#| eval: false
billboard |>
  pivot_longer(cols = "wk1":"wk76",
               names_to = "week",
               names_prefix = "wk",
               values_to = "position",
               values_drop_na = TRUE)
```

:::

---

## 🐣 Case study {#caso-práctico-3}

In the `{tidyr}` package we have the `who` dataset (World Health Organization dataset).

```{r}
#| eval: false
library(tidyr)
who
```


1. What do [**data**]{.hl-yellow} mean? How many [**variables and observations**]{.hl-yellow} do we have?

. . .

2. How many [**variable types**]{.hl-yellow} do we have?

. . .

3. Are all variables necessary? [**Remove redundant information**]{.hl-yellow}.

. . .

4. [**Convert to tidydata**]{.hl-yellow} the database by making all the options you consider (tip: use paper to sketch how the database should look like).



# Lesson 3: tidyverse (rows) {#clase-3}

[**Handling data by rows**]{style="color:#444442;"}

---


## What about tidyverse?

::: columns
::: {.column width="45%"}
![](img/tidyverrse_universe.jpg)
:::

::: {.column width="55%"}
- `{tibble}`: [**optimizing data.frame**]{.hl-yellow}
- `{tidyr}`: data cleaning
- `{readr}`: loading rectangular data (.csv)
- `{dplyr}`: [**grammar for debugging**]{.hl-yellow}
- `{stringr}`: text handling
- `{ggplot2}`: data visualization
- `{tidymodels}`: modeling/prediction
:::
:::

We also have the `{purrr}` packages for list management, `{forcast}` for qualitative variables, `{lubridate}` for dates, `{readxl}` for importing .xls and .xlsx files, `{rvest}` for web scraping and `{rmarkdown}` for reporting results.

---

## Preprocessing: dplyr

Within `{tidyverse}`, we will use the `{dplyr}` package for the [**preprocessing and debugging**]{.hl-yellow} of databases.

::: columns
::: {.column width="50%"}
All the debugging process that we are going to perform is on the [**assumption that our data is in tidydata format**]{.hl-yellow}
:::

::: {.column width="50%"}
![](img/tidy_def.jpg){width="160%"}
:::
::::

Remember that in `{tidyverse}` the [**pipe operator**]{.hl-yellow} defined as `|>` ([**ctrl+shift+M**]{.hl-purple}) will be crucial: it will be a [**pipe that traverses the data**]{.hl-yellow} and transforms it.

. . .

Let's practice with the `starwars` dataset from the loaded `{dplyr}` package.

```{r}
#| eval: false
library(tidyverse)
starwars
```

---

## Sampling

:::: columns
::: {.column width="60%"}

One of the most common operations is what is known in statistics as [**sampling**]{.hl-yellow}: a [**selection or filtering of records**]{.hl-yellow} (a subsample).

:::

::: {.column width="40%"}

![](img/muestreo.jpeg){width=500}
:::
::::

. . .


* [**Non-random (by quotas)**]{.hl-purple}: based on logical conditions on the records (`filter()`)

. . .

* [**Non-random (intentional/discretionary)**]{.hl-purple}: in terms of  position (`slice()`)

. . .

* [**Simple random**]{.hl-purple} (`slice_sample()`)

. . .

* [**Stratified simple sampling**]{.hl-purple} (`group_by()` + `slice_sample()`)



---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

The simplest one is when [**filter records**]{.hl-yellow} based on some logical condition: with `filter()` only individuals that verify certain conditions will be selected (non-random sampling by conditions).

::: incremental
-   `==`, `!=`: [**equal**]{.hl-purple} or [**different**]{.hl-yellow} to (`|> filter(variable == "a")`)
-   `>`, `<`: [**greater**]{.hl-purple} or [**less**]{.hl-yellow} than (`|> filter(variable < 3)`)
-   `>=`, `<=`: [**greater or equal**]{.hl-yellow} or [**less or equal**]{.hl-purple} to (`|> filter(variable >= 5)`)
-   `%in%`: values [**belong**]{.hl-yellow} to a valid set of options (`|> filter(variable %in% c("blue", "green"))`)
-   `between(variable, val1, val2)`: if continuous numerical values are [**within a range**]{.hl-yellow} (`|> filter(between(variable, 160, 180))`)
:::

---

## Filtering: filter()

These [**logical conditions**]{.hl-yellow} can be [**combined**]{.hl-yellow} in different ways (and, or, or mutually exclusive).

![](img/tablas_verdad.png)

. . .


::: callout-tip
## Important

Remember that inside `filter()` there must always be something that returns a [**vector of logical values**]{.hl-green}.

:::

---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about... [**filter**]{.hl-yellow} the characters with [**brown eyes**]{.hl-purple}?

. . .

[**What kind of variable is it?**]{.hl-yellow} --> The variable `eye_color` is qualitative so it is represented by texts.
. . .

```{r}
#| echo: false
#| include: false
library(tidyverse)
```

```{r}
starwars |>
  filter(eye_color == "brown")
```

---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about... [**filter**]{.hl-yellow} the characters without [**brown eyes**]{.hl-purple}?

. . .


```{r}
starwars |>
  filter(eye_color != "brown")
```

---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you go about... [**filter**]{.hl-yellow} the characters with [**brown or blue eyes**]{.hl-purple}?
. . .

```{r}
starwars |>
  filter(eye_color %in% c("blue", "brown"))
```

---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

Note that `%in%` is equivalent to concatenating several `==` with a conjunction or (`|`)

```{r}
starwars |>
  filter(eye_color == "blue" | eye_color == "brown")
```

---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::


How would you go about... [**filter**]{.hl-yellow} the characters  [**are between 120 and 160 cm**]{.hl-purple}?


. . .

[**What type of variable is it?**]{.hl-yellow} --> The variable `height` is a continuous quantitative variable so we must filter by ranges of values (intervals) --> we will use `between()`.

. . .

```{r}
starwars |>
  filter(between(height, 120, 160))
```


---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you... [**filter**]{.hl-yellow} characters that [**have brown eyes and are not human**]{.hl-purple}?

. . .

```{r}
starwars |>
  filter(eye_color == "brown" & species != "Human")
```

---

## Filtering: filter()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  filtro(condicion)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  filter(condition)
```
:::
:::

How would you... [**filter**]{.hl-yellow} characters that [**have eyes and are not human, or are over 60 years old**]{.hl-purple}? Think it through: the [**parentheses are important**]{.hl-yellow}: $(a+b)*c$ is not the same as $a+(b*c)$.

. . .

```{r}
starwars |>
  filter((eye_color == "brown" & species != "Human") | birth_year > 60)
```

---

## Drop missing: drop_na()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  retirar_ausentes(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na(var1, var2, ...)
```
:::
:::

There is a special filter for one of the most common operations in debugging: [**remove absent**]{.hl-yellow}. For this we can use inside a filter `is.na()`, which returns `TRUE/FALSE` depending on whether it is absent, or ....

. . .

Use `drop_na()`: if no variable is specified, it removes records with absent in any variable. Later we will see how to [**impute those missing ones**]{.hl-yellow} 

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na(mass, height)
```

```{r}
#| echo: false
starwars |>
  drop_na(mass, height, sex) |> 
  select(name, mass, height, hair_color) |> 
  slice(1:7)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na()
```

```{r}
#| echo: false
starwars |>
  drop_na() |> 
  select(name, mass, height, hair_color) |> 
  slice(1:7)
```
:::
:::

---

## 💻 Your turn {#tu-turno-3}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Select from the starwars dataset only those characters that are androids or whose `species` value is unknown.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter(species == "Droid" | is.na(species))
```

### [**Exercise 2**]{.hl-yellow}

📝 Select from the starwars dataset only the characters whose weight is between 65 and 90 kg.

```{r}
#| code-fold: true
#| eval: false
starwars |> filter(between(mass, 65, 90))
```

### [**Exercise 3**]{.hl-yellow}

📝 After clearing missing data in all variables, select from the starwars dataset only the characters that are human and come from Tatooine.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na() |> 
  filter(species == "Human" & homeworld == "Tatooine")
```

### [**Exercise 4**]{.hl-yellow}

📝 Select, from the original starwars dataset, non-human characters, `male` in sex and measuring between 120 and 170 cm, or characters with brown or red eyes.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter((species != "Human" & sex == "male" &
            between(height, 120, 170)) |
           eye_color %in% c("brown", "red"))
```

### [**Exercise 5**]{.hl-yellow}

📝 Check information about the `str_detect()` function (`{stringr}` package loaded in `{tidyverse}`). Tip: test the functions you are going to use with some test vector beforehand so that you can check how they work. After you know what it does, filter out only those characters with the last name `Skywalker`.

```{r}
#| code-fold: true
#| eval: false
starwars |> filter(str_detect(name, "Skywalker"))
```
:::

---

## Slice of data: slice()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> rebanadas(posiciones)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice(positions)
```
:::
:::

Sometimes we may be interested in performing a [**non-random discretionary sampling**]{.hl-yellow}, or in other words, [**filter by position**]{.hl-yellow}: with `slice(positions)` we can select specific rows by passing as argument a [**index vector**]{.hl-yellow}.

. . .

::: columns
::: {.column width="50%"}
```{r}
#| eval: false

# fila 1
starwars |>
  slice(1)
```

```{r}
#| echo: false
starwars |> slice(1) |> select(name:hair_color)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false

# filas de la 7 a la 9
starwars |>
  slice(7:9)
```

```{r}
#| echo: false
starwars |> slice(7:9) |> select(name:hair_color)
```
:::
:::

. . .

```{r}
#| eval: false

# filas 2, 7, 10 y 31
starwars |>
  slice(c(2, 7, 10, 31))
```

```{r}
#| echo: false
starwars |>
  slice(c(2, 7, 10, 31)) |> select(name:sex)
```

---

## Slice of data: slice()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  rebanadas(posiciones)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice(positions)
```
:::
:::

We have some default options:

* with `slice_head(n = ...)` and `slice_tail(n = ...)` we can get the [**header and tail**]{.hl-yellow} of the table.

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice_head(n = 2)
```

```{r}
#| echo: false
starwars |> slice_head(n = 2) |> select(name:hair_color)
```
:::

::: {.column width="\"50%"}
```{r}
#| eval: false
starwars |> slice_tail(n = 2)
```

```{r}
#| echo: false
starwars |> slice_tail(n = 2) |> select(name:hair_color)
```
:::
:::

---

## Slice of data: slice()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  rebanadas(posiciones)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice(positions)
```
:::
:::

We have some default options:

* with `slice_max()` and `slice_min()` we get the [**rows with smallest/largest value of a variable**]{.hl-yellow} (if tie, all unless `with_ties = FALSE`) that we indicate in `order_by = ...`.

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice_min(mass, n = 2)
```

```{r}
#| echo: false
starwars |> slice_min(n = 2, order_by = mass) |> select(name:hair_color)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> slice_max(height, n = 2)
```

```{r}
#| echo: false
starwars |> slice_max(n = 2, order_by = height) |> select(name:hair_color)
```
:::
:::

---

## Random slices: slice_sample()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  rebanadas_aleatorias(tamaño_muestral)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice_sample(sample_size)
```
:::
:::

The so-called [**simple random sampling**]{.hl-yellow} is based on [**selecting individuals randomly**]{.hl-yellow}, so that each one has certain [**probabilities**]{.hl-yellow} of being selected. With `slice_sample(n = ...)` we can randomly extract n (a priori equiprobable) records.

```{r}
starwars |> slice_sample(n = 2)
```

. . .

::: callout-important
## Important

[**«Randomness» does not imply equiprobable**]{.hl-yellow}: a normal die is just as random as a trick die. There are no things "more random" than others, they simply have different underlying probability laws.

:::

---

## Random slices: slice_sample()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  rebanadas_aleatorias(tamaño_muestral)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice_sample(sample_size)
```
:::
:::


We can also indicate the [**proportion of data to be sampled**]{.hl-yellow} (instead of the number) and if we want it to be [**with replacement (that can be repeated)**]{.hl-yellow}.

```{r}
# 5% de registros aleatorios con reemplazamiento
starwars |> 
  slice_sample(prop = 0.05, replace = TRUE)

```


---


## Random slices: slice_sample()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  rebanadas_aleatorias(tamaño_muestral)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  slice_sample(sample_size)
```
:::
:::


As we said, "random" is not the same as "equiprobable", so we can pass a [**probability vector**]{.hl-yellow}. For example, let's force that it is very improbable to draw a row other than the first two rows

```{r}
starwars |>
  slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85)))
```

. . .

```{r}
starwars |>
  slice_sample(n = 2, weight_by = c(0.495, 0.495, rep(0.01/85, 85)))
```

---

## A parenthesis: sample()

The `slice_sample()` function is simply a `{tidyverse}` integration of the basic `R` function known as `sample()` that allows us to [**sample elements**]{.hl-yellow}

. . .

For example, we are going to [**sample 10 rolls of a die**]{.hl-yellow}, indicating to it.

- [**support**]{.hl-purple} of our random variable (values allowed in `x`)
- [**size**]{.hl-purple} sample (`size`)
- [**replacement**]{.hl-purple} (if `TRUE` then it can come out repeated, as in the case of the die)

```{r}
sample(x = 1:6, size = 10, replace = TRUE)
```

---

## A parenthesis: sample()

The previous option generates events of a random variable [**equiprobable**]{.hl-yellow} but as before, we can assign a vector of probabilities or [**mass function**]{.hl-yellow} to it with the argument `prob = ...`.

```{r}
sample(x = 1:6, size = 50, replace = TRUE,
       prob = c(0.5, 0.2, 0.1, 0.1, 0.05, 0.05))
```

---


## A parenthesis: sample()

**How would you make the following statement?**

&nbsp;

Supongamos que en una ciudad se han estudiado los perfiles de votantes en parejas heterosexuales. Sean las variables aleatorias $X_m$ y $X_h$ tal que $X_m=1$ si una vota a un partido X, $X_m=0$ si no, $X_h=1$ si un hombre vota a un partido X y $X_p=0$ si no. El modelo teórico asociado a este tipo de electorado indica que la distribución conjunta viene dada por $P(X_m = 1, X_h=1)=0.02$, $P(X_m = 1, X_h=0)=0.08$, $P(X_m = 1, X_h=0)=0.1$ y $P(X_m = 0, X_h=0)=0.8$

**Generates a sample** of size $n = 1000$ (support `"10"`, `"01"`, `"00"` and `"11"`) using `sample()`.
---

## 💻 Your turn {#tu-turno-3a}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Select only the characters that are human and brown-eyed, then sort them in descending height and ascending weight.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter(eye_color == "brown" & species == "Human") |> 
  arrange(height, desc(mass))
```

### [**Exercise 2**]{.hl-yellow}

📝 Randomly extract 3 rows.

```{r}
#| code-fold: true
#| eval: false
starwars |> slice_sample(n = 3)
```

### [**Exercise 3**]{.hl-yellow}

📝 Sampling (randomly) 10% of data.

```{r}
#| code-fold: true
#| eval: false
starwars |> slice_sample(prop = 0.1)
```

### [**Exercise 4**]{.hl-yellow}

📝 Randomly draws 10 characters but in such a way that the probability of each character being drawn is proportional to its weight (heavier, more likely).

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(mass) |> 
  slice_sample(n = 10, weight_by = mass)
```

### [**Exercise 5**]{.hl-yellow}

📝 Select the 3 oldest characters.

```{r}
#| code-fold: true
#| eval: false
starwars |> slice_max(birth_year, n = 3)
```


:::


---

## Rearrange rows: arrange()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> ordenar(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> arrange(var1, var2, ...)
```
:::
:::

We can also [**order rows**]{.hl-yellow} according to some variable with `arrange()`.

```{r}
#| eval: false
starwars |> arrange(mass)
```

```{r}
#| echo: false
starwars |> arrange(mass) |> select(name:eye_color) |> slice(1:5) 
```

. . .

By default, arranging is done [**from lowest to highest**]{.hl-yellow} but we can [**reverse the order**]{.hl-purple} with `desc()`.

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |> arrange(desc(height))
```

```{r}
#| echo: false
starwars |> arrange(desc(height)) |> select(name:mass) |> slice(1:5) 
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> arrange(mass, desc(height))
```

```{r}
#| echo: false
starwars |> arrange(mass, desc(height)) |> select(name:mass) |> slice(1:5) 
```
:::
:::

---

## Remove duplicates: distinct()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> sin_duplicados(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> distinct(var1, var2, ...)
```
:::
:::

Many times we will need to make sure that there are no duplicates in some variable (DNI) and we can [**delete duplicate rows**]{.hl-yellow} with `distinct()`.

```{r}
starwars |> distinct(sex)
```

. . .

To keep all variables we will use `.keep_all = TRUE`.

```{r}
#| eval: false
starwars |> distinct(sex, .keep_all = TRUE)
```

```{r}
#| echo: false
starwars |> distinct(sex, .keep_all = TRUE) |> slice(1:3)
```

---

## Add rows: bind_rows()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
tibble1 |> encuadernar_filas(tibble2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
tibble1 |> bind_rows(tibble2)
```
:::
:::

Finally, we can [**bind new rows**]{.hl-yellow} with `bind_rows()` with [**new observations in table**]{.hl-red} (if columns do not match fill with missing data)

```{r}
datos <-
  tibble("names" = c("javi", "laura"), "ages" = c(33, 50))
datos
```

. . .

```{r}
datos |> bind_rows(tibble("names" = c("carlos", NA), "zip" = c(28045, 28019)))
```

---

## 💻 Your turn {#tu-turno-3b}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 To find out what unique values are in the hair color, remove duplicates of the `hair_color` variable by first removing the missing ones from the `hair_color` variable.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(hair_color) |> 
  distinct(hair_color)
```

### [**Exercise 2**]{.hl-yellow}

📝 Just considering the characters that are human and taller than 160 cm, eliminate duplicates in eye color, eliminate missing data in weight, select the 3 tallest, and order from tallest to shortest in weight. Return the table.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  filter(species == "Human" & height > 160) |> 
  distinct(eye_color, .keep_all = TRUE) |> 
  drop_na(mass) |> 
  slice_max(height, n = 3) |> 
  arrange(desc(mass))
```
:::

---

## In summary

The key to `{tidyverse}` is the [**legibility**]{.hl-yellow}: it is very important that the code is understood, for our future self but also for the [**algorithmic transparency**]{.hl-yellow} towards the others

[**For example**]{.hl-purple}: we will remove absent from the weight variable, we will filter the human characters and height higher than 140cm, without duplicates in the hair color, extracting the 5 tallest and obtaining 2 random characters finally.


::: columns
::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  elimino_ausentes(peso) |> 
  filtro(especie humana Y altura > 140 cm) |> 
  sin_duplicados(color de pelo) |>
  rebanadas_max(peso, n = 5) |> 
  rebanadas_aleatorias(n = 2)
```
:::


::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  drop_na(mass) |> 
  filter(species == "Human" & height > 140) |> 
  distinct(hair_color, .keep_all = TRUE) |>
  slice_max(mass, n = 5) |> 
  slice_sample(n = 2)
```
:::
:::


--- 

## 🐣 Case study {#caso-práctico-3}

We are going to use the `biopsy` dataset that can be found in the dataset aggregator <https://vincentarelbundock.github.io/Rdatasets/index.html>. The [**dataset contains data from 699 patients who underwent a breast biopsy**]{.hl-yellow}, obtaining 11 variables (one id and 10 scales measured from 1 to 10).

You can see the documentation at <https://vincentarelbundock.github.io/Rdatasets/doc/MASS/biopsy.html>
. . .

1. [**Load the dataset**]{.hl-yellow} from the `{MASS}` package.
. . .

2. The variable `ID` should be the identifier of each record: [**eliminate duplicates**]{.hl-yellow} for that variable of the previous dataset.

---

## 🐣 Case study {#caso-práctico-3a}

3. From the above dataset [**filter**]{.hl-yellow} only patients with malignant tumor and the variable `V9` with value 4 or lower, [**further deleting any records containing missing data**]{.hl-yellow} in any of the variables.

. . .

4. From the above dataset obtain a [**sample of 20% of the data**]{.hl-yellow} (each record can be chosen with the same probability), and [**sort them**]{.hl-yellow} from highest to lowest by the variable `V1` and, in case of a tie, from lowest to highest by the variable `V2`.


# Lesson 4: tidyverse (columns) {#clase-4}

[**Handling data by columns**]{style="color:#444442;"}

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> selecciono(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

The simplest option for [**selecting variables by name**]{.hl-yellow} is using `select()`, as arguments the column names [**without quotes**]{.hl-purple}.

```{r}
starwars |> select(name, hair_color)
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> selecciono(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

`select()` allows us to select many variables at once, even [**concatenating their names as if they were numerical indexes**]{.hl-yellow}

```{r}
#| eval: false
starwars |> select(name:eye_color) 
```

```{r}
#| echo: false
starwars |> select(name:eye_color) |> slice(1:4)
```

. . .

And we can [**remove (unselect) columns**]{.hl-yellow} using `-` before

```{r}
#| eval: false
starwars |>  select(-mass, -(eye_color:starships))
```

```{r}
#| echo: false
starwars |> select(-mass, -(eye_color:starships)) |> slice(1:4)
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> selecciono(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

We have also [**reserved selectors**]{.hl-yellow}: `everything()` for [**all variables**]{.hl-purple}....

```{r}
#| eval: false
starwars |> select(mass, homeworld, everything())
```

```{r}
#| echo: false
starwars |> select(mass, homeworld, everything()) |> slice(1:4)
```

. . .

...and `last_col()` for [**last column**]{.hl-purple}.

```{r}
#| eval: false
starwars |> select(name:mass, homeworld, last_col())
```

```{r}
#| echo: false
starwars |> select(name:mass, homeworld, last_col()) |> slice(1:4)
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> selecciono(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

We can also find  [**patterns**]{.hl-yellow} in the name, those that [**begin with a prefix**]{.hl-purple} (`starts_with()`), [**end with a suffix**]{. hl-purple} (`ends_with()`), [**contain text**]{.hl-purple} (`contains()`) or fulfill a [**regular expression**]{.hl-purple} (`matches()`).


```{r}
starwars |> select(ends_with("color"), matches("sex|gender"))
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> selecciono(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

We can even [**select by numeric range**]{.hl-yellow} if we have variables with a prefix and numbers.

```{r}
data <-
  tibble("wk1" = c(115, 141, 232), "wk2" = c(7, NA, 17),
         "wk3" = c(95, 162, NA), "wk4" = c(11, 19, 15),
         "wk5" = c(NA, 262, 190), "wk6" = c(21, 15, 23))
```

. . .

`num_range()` allows us to select by prefix and a numeric sequence

```{r}
data |> select(num_range("wk", 1:4))
```

---

## Select columns: select()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> selecciono(var1, var2, ...)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> select(var1, var2, ...)
```
:::
:::

Finally, we can select columns by [**datatatype**]{.hl-yellow} using `where()` and inside a function that returns a logical value of datatype.

```{r}
# Just numeric or string columns
starwars |> select(where(is.numeric) | where(is.character))
```

---

## Relocate columns: relocate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  recolocar(var1, despues_de = var2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  relocate(var1, .after = var2)
```
:::
:::

To facilitate the [**relocation of variables**]{.hl-yellow} we have a function for it, `relocate()`, indicating in `.after` or `.before` [**behind**]{.hl-purple} or [**in front**]{.hl-purple} of which columns we want to move them.

```{r}
starwars |> relocate(species, .before = name)
```

---

## Rename columns: rename()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> renombrar(nuevo = antiguo)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> rename(new = old)
```
:::
:::

Sometimes we may also want to [**modify the "meta-information "**]{.hl-yellow} of the data, [**renaming columns**]{.hl-yellow}. To do this we will use `rename()` by putting [**first the new name**]{.hl-purple} and then the [**old**]{.hl-purple}.

```{r}
starwars |> rename(nombre = name, altura = height, peso = mass)
```

---

## Extract columns: pull()


::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> retirar(var)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> pull(var)
```
:::
:::


If you look at the output of the `select()` [**it is still a tibble**]{.hl-yellow} table, as it preserves the nature of our data.

```{r}
starwars |> select(name)
```

---


## Extract columns: pull()


::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> retirar(var)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> pull(var)
```
:::
:::


Sometimes we will not want such a structure but [**literally extract the column into a vector**]{.hl-yellow}, and we can do it with `pull()`.

```{r}
starwars |> pull(name)
```


---


## 💻 Your turn {#tu-turno-4a}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}


::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Filter the set of characters and keep only those that in the `height` variable do not have a missing data. With the data obtained from the previous filter, select only the variables name, height, as well as all those variables that CONTAIN the word color in their name.

### [**Exercise 2**]{.hl-yellow}

📝 With the data obtained from the previous exercise, translate the names of the columns into English.

### [**Exercise 3**]{.hl-yellow}

📝 With the data obtained from the previous exercise, place the hair color variable just behind the name variable.

### [**Exercise 4**]{.hl-yellow}

📝 With the data obtained from the previous exercise, check how many unique modes there are in the hair color variable (without using `unique()`).

### [**Exercise 5**]{.hl-yellow}

📝 From the original data set, it removes the list type columns, and then removes duplicates in the `eye_color` variable. After removing duplicates it extracts that column into a vector.

:::

---


## Modify columns: mutate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> modificar(nueva = funcion())
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> mutate(new = function())
```
:::
:::

In many occasions we will want to [**modify or create variables**]{.hl-yellow} with `mutate()`. 


. . . 

Let's create for example a new variable `height_m` with the height in meters.

```{r}
starwars |> mutate(height_m = height / 100)
```

---

## Modify columns: mutate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> modificar(nueva = funcion())
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> mutate(new = function())
```
:::
:::

In addition, with optional arguments as `.before` or `.after` we can [**relocate the modified column**]{.hl-yellow}

```{r}
starwars |> 
  mutate(height_m = height / 100,
         IMC = mass / (height_m^2), .before = name)
```

---

## Modify columns: mutate()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> modificar(nueva = funcion())
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> mutate(new = function())
```
:::
:::

::: callout-important
## Important...

When we apply `mutate()`, we must remember that the [**operations are performed in a vectorial way**]{.hl-yellow}, element by element, so the function we use inside must return a vector of equal length. Otherwise, [**it will return a constant**]{.hl-red}
:::

. . .

```{r}
starwars |> 
  mutate(cte = mean(mass, na.rm = TRUE), .before = name)
```

---


## Recat: if_else()

We can also combine `mutate()` with the `if_else()` control expression to [**recategorize the variable**]{.hl-yellow}: if [**a condition is verified**]{.hl-purple}, it does the first option, otherwise the second one.

```{r}
starwars |> 
  mutate(human = if_else(species == "Human", "Human", "Not Human"),
         .after = name) |> 
  select(name:mass)
```

---

## Recat: case_when()

For [**more complex categorizations**]{.hl-yellow} we have `case_when()`, for example, to create a category of characters based on their height.

```{r}
starwars |> 
  drop_na(height) |> 
  mutate(altura = case_when(is.na(height) ~ NA,
                            height < 120 ~ "tiny",
                            height < 160 ~ "short",
                            height < 180 ~ "normal",
                            height < 200 ~ "tall",
                            TRUE ~ "gigant"), .before = name)
```

---

## 💻 Your turn {#tu-turno-4b}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Select just variables `name`, `height` and as well as all those variables related to color properties, while keeping only those that are not absent in the height.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  select(name, height, contains("color")) |> 
  drop_na(height)
```

### [**Exercise 2**]{.hl-yellow}

📝 With the data obtained from the previous exercise, translate the names of the columns into English.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  select(name, height, contains("color")) |> 
  drop_na(height) |> 
  rename(nombre = name, altura = height,
         color_pelo = eye_color, color_piel = skin_color,
         color_pelo = hair_color)
```

### [**Exercise 3**]{.hl-yellow}

📝 With the data obtained from the previous exercise, relocate the hair color variable just behind the name variable.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  select(name, height, contains("color")) |> 
  drop_na(height) |> 
  rename(nombre = name, altura = height,
         color_pelo = eye_color, color_piel = skin_color,
         color_pelo = hair_color) |> 
  relocate(color_pelo, .after = nombre)
```

### [**Exercise 4**]{.hl-yellow}

📝 Using the original data, check how many unique modes there are in the hair color variable.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  distinct(hair_color) |> 
  nrow()
```

### [**Exercise 5**]{.hl-yellow}

📝 From the original dataset, select only the numeric and text variables. Then define a new variable called `under_18` to recategorize the age variable: `TRUE` if it is under age and `FALSE` otherwise.

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  select(where(is.numeric) | where(is.character)) |> 
  mutate(under_18 = birth_year < 18)
```

### [**Exercise 6**]{.hl-yellow}

📝 From the original dataset, create a new column named `auburn` that tells us TRUE if the hair color contains that word and FALSE otherwise (reminder `str_detect()`).

```{r}
#| code-fold: true
#| eval: false
starwars |> 
  mutate(auburn = str_detect(hair_color, "auburn"))
```

:::

---

## 🐣 Case study I {#caso4}

From the original dataset, include a column that calculates the BMI. After that, create a new variable that values `NA` if not human, `thin` below 18, `normal` between 18 and 30, `overweight` above 30.


---

## 🐣 Case study II {#caso4a}


Let's proceed to [**create a table with data of voters**]{.hl-yellow} of size `n = 30` where [**simulate the voting intention and their incomes**]{.hl-yellow}

. . .

1. Create a `tibble` with two columns, one named `id_voter` and one named `party`. In the first case it should go from 1 to 30. In the second case, it simulates its voting intention so that there is a 0.5 chance of `PP` and 0.5 chance of `SUMAR` (Spanish political parties).
. . .

2. After knowing the voting intention, create a third column called `income` in which you simulate their gross annual income. We will assume that for PP's voterts, incomes follows a distribution $N(\mu = 37000€, sigma = 800)$ and that for SUMAR's voters it follows a distribution $N(\mu = 26000€, sigma = 1200)$.

# Lesson 5: tidyverse (summary)  {#clase-5}

[**Summarizing data**]{style="color:#444442;"}

---

## Count: count()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> contar(var1, var2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> count(var1, var2)
```
:::
:::

So far we have only transformed or queried the data but have not generated statistics. Let's start with the simple: [**how to count (frequencies)?**]{.hl-yellow}

. . .

When used alone `count()` will simply return the number of records, but when used with `count()` variables it calculates what is known as [**frequencies**]{.hl-yellow}: [**number of elements of each modality**]{.hl-purple}.

```{r}
starwars |> count(sex)
```

---

## Count: count()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> contar(var1, var2)
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> count(var1, var2)
```
:::
:::

Also if we include several variables it calculates what is known as a [**contiguity table**]{.hl-yellow}. With `sort = TRUE` it will return the [**ordered count**]{.hl-purple} (most frequent first).

```{r}
starwars |> count(sex, gender, sort = TRUE)
```

---

## Groups: group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  agrupar(var1, var2) |> 
  accion() |> 
  desagrupar()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  action() |> 
  ungroup()
```
:::
:::

One of the most powerful [**functions**]{.hl-yellow} to combine with the actions seen is `group_by()`, which will allow us to [**group our records**]{.hl-yellow} beforehand.

```{r}
starwars |> 
  group_by(sex) |>
  count() |>
  ungroup()
```

---

## Groups: group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  agrupar(var1, var2) |> 
  accion() |> 
  desagrupar()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  action() |> 
  ungroup()
```
:::
:::

When applying `group_by()` it is important to understand that it [**DOES NOT MODIFY the data**]{.hl-yellow}, but creates a [**group variable**]{.hl-yellow} (sub-tables for each group) that will modify future actions: the [**operations will be applied to each sub-table separately**]{.hl-purple}

. . .

For example, let us imagine that we want to extract the highest character with `slice_max()`.

```{r}
starwars |> slice_max(height)
```


---

## Groups: group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  agrupar(var1, var2) |> 
  accion() |> 
  desagrupar()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  action() |> 
  ungroup()
```
:::
:::

What if we want to [**extract the tallest character but...of each of the sexes**]{.hl-yellow}?

. . .

```{r}
starwars |>
  group_by(sex) |> 
  slice_max(height) |> 
  ungroup()
```

---

## Groups: group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  agrupar(var1, var2) |> 
  accion() |> 
  desagrupar()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  action() |> 
  ungroup()
```
:::
:::

::: columns
::: {.column width="50%"}
![](img/tidydatatutor_1.jpg)
:::

::: {.column width="50%"}
![](img/tidydatatutor_2.jpg)
:::
:::

The website <https://tidydatatutor.com/> allows to visualize the operations of `{tidyverse}` (with the old pipe)

---

## Groups: group_by()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |>
  agrupar(var1, var2) |> 
  accion() |>
  desagrupar()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |>
  group_by(var1, var2) |> 
  action() |>
  ungroup()
```
:::
:::

::: callout-important
## Important

Reminder: [**make ungroup**]{.hl-red} to remove the created group variable
:::

. . .

The new version of `{dplyr}` package now [**allows to include the group variable**]{.hl-yellow} in the call to many functions with the argument `by = ...` or `.by = ...`.

```{r}
#| eval: false
starwars |> slice_max(height, by = sex)
```

```{r}
#| echo: false
starwars |> slice_max(height, by = sex) |> select(name:eye_color)
```

---

## Row-by-row: rowwise()

A very useful option used before an operation is also `rowwise()`: every [**operation that comes afterwards will be applied on each row separately**]{.hl-yellow}. For example, let's define a dummy set of notes.

```{r}
marks <- tibble("maths" = c(7.5, 8, 9.1, 3),
                "lang" = c(8, 6, 6.5, 9.2))
```

. . .

If we apply the average directly the value will be identical since it has done the global average, but we would like to get an [**average per row**]{.hl-yellow}. For that we will use `rowwise()`.

```{r}
marks |> 
  rowwise() |> 
  mutate(avg_mark = mean(c(maths, lang)))
```

---

## Summary: summarise()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> resumir()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> summarise()
```
:::
:::

Finally we have `summarise()`, which will allow us to get statistical summaries. For example, let's [**calculate the average of the heights**]{.hl-yellow}.

```{r}
starwars |> 
  drop_na(height) |> 
  summarise(media_altura = mean(height))
```

. . .

::: callout-warning
## Be careful...

Notice that `mutate()` returns [**as many rows as original records**]{.hl-yellow}, while with `summarise()` it calculates a [**new summary dataset**]{.hl-purple}, only including what is indicated.

:::

---

## Summary: summarise()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> resumir()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> summarise()
```
:::
:::

If we also [**combine this with the grouping action**]{.hl-yellow} of `group_by()` or `.by = ...`, in a few lines of code you can get [**disaggregated statistics**]{.hl-purple}.

```{r}
starwars |> 
  drop_na(sex, height, mass) |> 
  summarise(mean_height = mean(height),
            mean_mass = mean(mass),
            .by = sex)
```

---

## Summary: summarise()

::: columns
::: {.column width="50%"}
```{r}
#| eval: false
datos |> resumir()
```
:::

::: {.column width="50%"}
```{r}
#| eval: false
starwars |> reframe()
```
:::
:::

In the new `{dplyr}` version, they have included `reframe()` to avoid problems with `summarise()` when [**we return more than one value per variable**]{.hl-yellow}.

::: columns
::: {.column width="50%"}
```{r}
#| warning: true
starwars |>
  drop_na(mass) |>
  summarise(quantile(mass))
```
:::

::: {.column width="50%"}
```{r}
starwars |>
  drop_na(mass) |>
  reframe(quantile(mass))
```
:::
:::

---

## Selectors: across()

One trick is to [**make use of selectors**]{.hl-yellow} `across()` and `where()`. The former allows us to [**act on several columns by name**]{.hl-purple} (with `mutate()` or `summarise()`).

```{r}
starwars |> summarise(means = across(height:mass, mean, na.rm = TRUE), .by = sex)
```

. . .

The second one, `where()`, allows us to do the same but [**selecting by type**]{.hl-yellow}.

```{r}
starwars |> 
  summarise(across(where(is.numeric), mean, na.rm = TRUE), .by = c(sex, gender))
```

---

## 💻 Your turn {#tu-turno-5a}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 Compute how many characters there are of each species, ordered from most to least frequent.

```{r}
#| code-fold: true
#| eval: false
starwars |> count(species, sort = TRUE)
```

### [**Exercise 2**]{.hl-yellow}

📝 After removing missing variables for weight and height, add a new variable to calculate the BMI of each character, and determine the average BMI of our characters disaggregated by gender.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(mass, height) |> 
  mutate(BMI = mass / ((height/100)^2)) |> 
  summarise(mean_BMI = mean(BMI), .by = sex)
```

### [**Exercise 3**]{.hl-yellow}

📝 Obtain the youngest character for each gender.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  slice_min(birth_year, by = sex)
```

### [**Exercise 4**]{.hl-yellow}

📝 Get the age of the youngest and oldest character, in general and for each of sex modalities.

```{r}
#| code-fold: true
#| eval: false
starwars |>
  drop_na(birth_year) |>
  summarise(min(birth_year), max(birth_year))

starwars |>
  drop_na(birth_year) |>
  summarise(min(birth_year), max(birth_year), .by = sex)
```


:::



---

## 🐣 Case study I {#caso5a}

Let us randomly select 50% of the data, keeping the original distribution (in proportions) between humans and non-humans (we should remove first missing values).

. . .

Then keep only the variables name, height, those representing a color characteristic and the variable films. Calculate the average heights in humans and non-humans. Finally calculate the frequencies of eye color and human/non-human.

--- 


## Report: rmd y Quarto

One of the [**main strengths**]{.hl-yellow} of `R` is the [**easiness to generate reports, books, webs, notes and even slides**]{.hl-yellow} (this material for example). To do this, [**install**]{.hl-purple} before

::: columns
::: {.column width="40%"}
-   package `{rmarkdown}` (allows us to generate `.rmd` files)

```{r}
#| eval: false
install.packages("rmarkdown")
```

- install [**Quarto**](https://quarto.org/docs/get-started/) (the «new» `.rmd` files, names as `.qmd`)
:::

::: {.column width="60%"}
![](img/quarto.png)
:::
:::

---

## Report: rmd y Quarto

So far we have only programmed in scripts (`.R` files) within projects, but in many occasions [**we will not work alone**]{.hl-yellow} and we will need to [**communicate the results**]{.hl-yellow} in different formats:

- notes (for ourselves)
- slides
- web
- reports

. . .
 
For all of this we will use [**Quarto (new rmarkdown)**]{.hl-yellow}


---

## Report: rmd y Quarto

The `.qmd` (or `.rmd`) extension files will allow us to easily combine:

- [**Markdown**]{.hl-yellow}: [**typed language**]{.hl-purple} which allows us to create simple content (wordpress type, with text, **bold**, _cursives_, etc) with a readable layout.

. . .

- [**Math (latex)**]{.hl-yellow}: language for writing mathematical notation such as $x^2$ or $$sqrt{y}$ or $$int_{a}^{b} f(x) dx$.

. . .

- [**Code and outputs**]{.hl-yellow}: we will be able to show not only the final step but also the code you have been doing (not only in `R`), with [**code boxes called chunks**]{.hl-purple} .

. . .

- Images, [**graphics**]{.hl-yellow}, tables, styles (css, js), etc.

---

## Report: rmd y Quarto

The main advantage of making this type of material in Quarto/Rmarkdown is that, by doing it from `RStudio`, you can generate a [**report or presentation without leaving the programming environment**]{.hl-yellow} in which you are working.

This way you can analyze the data, summarize it and at the same time report it with the same tool.

. . .

Recently the `RStudio` team developed [**Quarto**]{.hl-yellow}, an improved version of Rmarkdown (`.qmd` files), with a slightly more aesthetic and simple format. You have all the documentation and examples at [**https://quarto.org/**](https://quarto.org/)


---

## Our first report

::: columns
::: {.column width="55%"}
![](img/quarto-create.png)
:::

::: {.column width="45%"}
We are going to create the [**first rmarkdown file with Quarto**]{.hl-yellow} with extension `.qmd`. For this we will only need to click on

`File << New File << Quarto Document`
:::
:::

---

##  Our first report

:::: columns
::: {.column width="45%"}
![](img/quarto-format.png)
:::

::: {.column width="55%"}
After doing so we will be presented with several [**output format options**]{.hl-yellow}:

- `.pdf` file
- file `.html` ([**recommendable**]{.hl-yellow}): dynamic document, allows interaction with the user, like a "web page".
- `.doc` file (not recommended)
:::
::::

. . .

For the moment we will leave the [**default HTML format**]{.hl-yellow} checked, and we will write the [**title**]{.hl-yellow} of our document. After that we will have our [**file .qmd**]{.hl-yellow} (it is no longer an .R script like the ones we have opened so far).

---

##  Our first report

:::: columns
::: {.column width="60%"}
![](img/quarto-example.png)
:::

::: {.column width="40%"}

You should have something similar to the image capture with [**two editing modes**]{.hl-yellow}: `Source` (with code, the recommended option until you master it) and `Visual` (more like a blog).

:::
::::

To [**run the ENTIRE document**]{.hl-yellow} you must click `Render on Save` and hit save.

![](img/quarto-prueba-html.png)

You should have obtained an [**html output similar to this**]{.hl-yellow} (and a [**html file**]{.hl-yellow} has been generated on your pc).

---

##  Our first report

:::: columns
::: {.column width="50%"}
![](img/quarto-example.png)

:::

::: {.column width="50%"}

A `.qmd` file is [**basically divided into three parts**]{.hl-yellow}:

* [**Header**]{.hl-yellow}: the part you have at the beginning between `---`.

* [**Text**]{.hl-yellow}: that we can format and enhance with bold (written as **bold**, with double asterisk at the beginning and end), italics (_cursive_, with underscore at the beginning and end) or highlight function names or variables of R. You can add equations like $x^2$ (I have written `$x^2$`, between dollars).

* [**R code**]{.hl-yellow}

:::
::::

---

## qmd header

The [**header is in YAML**]{.hl-yellow} format and contains the [**metadata**]{.hl-yellow} of the document:

:::: columns
::: {.column width="30%"}
![](img/quarto-cabecera.png)
:::

::: {.column width="70%"}

* `title` and `subtitle`: document title/subtitle
* `author`: author of the document
* `date`: date
* ``format`: output format (we can customize it)
  * `theme`: if you have any style file
  * `toc`: if you want index or not
  * `toc-location`: index position
  * `toc-title`: index title
  * `toc-depth`: index depth
* `editor`: if you are in visual or source mode.

:::
::::

---

## Text

As for writing there is only one [**important thing**]{.hl-yellow}: unless we indicate otherwise, [**EVERYTHING we are going to write is (normal)** text]{.hl-yellow}. No R code.


:::: columns
::: {.column width="35%"}
![](img/quarto-prueba-qmd2.png){width=350}
![](img/quarto-prueba-html2.png){width=320}
:::

::: {.column width="65%"}
We are going to start by writing a section at the beginning (`# Intro` and behind it e.g. the phrase

> This material has been designed by Javier Álvarez Liébana, professor at the Complutense University of Madrid.

In addition to the `Running Code` we will add a `#`: the [**OUT OF CHUNKS**]{.hl-yellow} `#` will be used to create [**epigraphs (sections)**]{.hl-yellow} in the document.


:::
::::


---

## Table of contents

:::: columns
::: {.column width="40%"}
![](img/quarto-indice-qmd-2.png){width=370}
![](img/quarto-indice-html2.png){width=370}
:::

::: {.column width="60%"}
To make the [**index capture those sections**]{.hl-yellow} we will modify the header of the file as shown in the image (you can change the location of the index and the title if you want to test).

:::
::::

---

## Text

Let's [**customize the text**]{.hl-yellow} by doing the following:

:::: columns
::: {.column width="50%"}
![](img/quarto-texto-mejorado-qmd.png){width=370}
![](img/quarto-texto-mejorado-html.png){width=370}
:::

::: {.column width="50%"}
* Let's add [**bold to the name**]{.hl-yellow} (putting ** at the beginning and at the end).

* Let's add [**cursive**]{.hl-yellow} to the word material (putting _ at the beginning and at the end).

* Let's add a [**link**]{.hl-yellow} <https://www.ucm.es>, associating it to the name of the University. To do this we put the title in square brackets and just behind the link in brackets `["Universidad Complutense de Madrid"](https://www.ucm.es)`.

:::
::::

---

## Code

To [**add R code**]{.hl-yellow} we must create our [**code boxes called chunks**]{.hl-yellow}: high in the path in our markdown text where we can include code from almost any language (and its outputs).

&nbsp;

:::: columns
::: {.column width="50%"}
![](img/quarto-chunk-qmd.png){width=470}
:::

::: {.column width="50%"}

To include one you must go [**header**]{.hl-yellow} as follows you have a shortcut `Command + Option + I` (Mac) or `Ctrl + Shift + I` (Windows)
:::

::::

---

## Code

Inside this box (which now has a different color in the document) [**write code R**]{.hl-yellow} as we have been doing so far in the scripts.

:::: columns
::: {.column width="50%"}
![](img/quarto-chunk-1-qmd.png){width=410}
![](img/quarto-chunk-1-html.png){width=410}
:::

::: {.column width="50%"}

Let's for example define two variables and their sum in the following way, writing this code in our `.qmd` (inside that chunk).

```{r}
# R code
x <- 1
y <- 2
x + y
```

:::

::::


---

## Labelling chunks


:::: columns
::: {.column width="50%"}
![](img/quarto-tag-chunks-qmd.png){width=400}
![](img/quarto-tag-chunks-html.png){width=400}
:::

::: {.column width="50%"}
Chunks can have a [**name or tag**]{.hl-yellow}, so that we can reference them again to avoid repeating code.
:::
::::


---

## Running chunks

:::: columns
::: {.column width="40%"}
![](img/quarto-inline-qmd.png){width=400}
![](img/quarto-inline-html.png){width=380}
:::

::: {.column width="60%"}
In each chunk there are [**two buttons**]{.hl-yellow}:

* [**play**]{.hl-yellow} button: activates the [**run and exit of that particular chunk**]{.hl-yellow} (you can view it within your own `RStudio`)

* [**rewind**]{.hl-yellow} button: triggers [**execute and exit all chunks up to that one**]{.hl-yellow} (without getting to it)

&nbsp;

In addition we can [**include R code inside the text line**]{.hl-yellow} (instead of displaying the text x execute the R code displaying the variable).
:::
::::



---

## Customizing chunks

The [**chunks can be customized**]{.hl-yellow} with options at the beginning of the chunk preceded by `#|`:

* ` `#| echo: false`: [**execute code**]{.hl-green} and it [**shows result**]{.hl-green} but [**does not display code**]{.hl-red} in the output.

* `#| include: false`: [**executes code**]{.hl-green} but [**does not display result**]{.hl-red} and [**does not display code**]{.hl-red} in the output.

* `#| eval: false`: [**does not execute code**]{.hl-red}, [**does not display result**]{.hl-red} but [**does display code**]{.hl-green} on output.

* `#| message: false`: [**executes code**]{.hl-green} but [**does not display output messages**]{.hl-red}.

* `#| warning: false`: [**executes code**]{.hl-green} but [**does not display warning messages**]{.hl-red}.

* `#| error: true`: [**executes code**]{.hl-green} and [**allows errors**]{.hl-green} showing the error message in the output.


![](img/quarto-options-chunk.png){width=380}

These options can be applied chunk by chunk or set globally with `knitr::opts_chunk$set()` at the beginning of the document (within a chunk).

---

## Organizing qmd

In addition to text and code we can enter the following:

* [**Equations**]{.hl-yellow}: you can additionally add equations such as $x^2$ (I have written `$x^2$`, the equation between dollars).

* [**Lists**]{.hl-yellow}: you can itemize elements by putting `*`

`* Step 1: ...`

`* Step 2: ...`

* [**Cross-references**]{.hl-yellow}: you can tag parts of the document (the tag is constructed with `{#section-name}`) and then call them with `[Section](@section-name)`).

---

## Graphics/images

:::: columns
::: {.column width="50%"}
![](img/quarto-fig-qmd.png){width=340}
![](img/quarto-fig-html.png){width=390}
:::

::: {.column width="50%"}
Por último, también podemos [**añadir pies de gráficas o imágenes**]{.hl-yellow} añadiendo `#| fig-cap: "..."`
:::
::::

. . .

:::: columns
::: {.column width="65%"}
Finally, we can also [**add captions to graphics or images**]{.hl-yellow} by adding `#| fig-cap: "..."`.
:::

::: {.column width="35%"}
![](img/quarto-cabecera-desplegable.png){width=400}
:::
::::

---

## Theme and styles

:::: columns
::: {.column width="50%"}
![](img/quarto-estilos-qmd.png){width=400}
![](img/quarto-estilos-html.png){width=400}
:::

::: {.column width="50%"}
Finally, you can add a [**custom theme**]{.hl-yellow} including a [**style file**]{.hl-yellow} (`.scss` or `.css` file). I have left one for you at <https://github.com/dadosdelaplace/mucss-data-programming/tree/main/material>.

::: callout-important
## Important

The style file must be in the same folder as the `.qmd` file.
:::
:::
::::

---

## 🐣 Case study {#caso5b}

Produce a `.qmd` report such that.

* Create a file make [**one section per exercise**]{.hl-yellow} (see the following slides)

* [**Detail all the steps**]{.hl-yellow} you consider mixing text, code and outputs .

* If statistical measures such as the mean appear, [**try entering formulas**]{.hl-yellow} with `$$` (look for information on how to enter equations in latex).

---

## 🐣 Case study

1. Loads the billboard datatable from the `{tidyr}` package.

. . .

2. First of all, select only the [**first 52 weeks**]{.hl-yellow} (but also artist, track and date variables). After that convert the dataset to [**tidydata**]{.hl-yellow} with the appropriate formats and types for each variable

. . .

3. Extracts the [**list of distinct artists**]{.hl-yellow} appearing in the table, including [**how many times**]{.hl-yellow} each appears.

. . .

4. Determines [**how many songs each artist**]{.hl-yellow} has

---

## 🐣 Case study


5. Determines the [**5 songs that appear in the charts the most weeks**]{.hl-yellow}. 


. . .

6. Determines [**for each artist the song that appears the most weeks**]{.hl-yellow}. 


. . .

7. Determines the [**artist with the most songs**]{.hl-yellow} in the list

. . .

8. Calculates the [**highest position**]{.hl-yellow} that each song has been on. Calculates the highest position an artist has been in.

---

## 🐣 Case study

9. Get a [**summary table**]{.hl-yellow} with the average ranking of each artist (counting only the highest ranking achieved by their songs), as well as the number of (different) songs they have placed in the top 100.

. . .

10. Perform stratified random sampling, extracting 50% of the data but maintaining the proportion of data among the different quarters.

# Lesson 6: import/export {#clase-6}

[**Import/export and functions**]{style="color:#444442;"}

---

## 🐣 Case study 3

We are going to use the `biopsy` dataset that can be found in the dataset aggregator <https://vincentarelbundock.github.io/Rdatasets/index.html>. The [**dataset contains data from 699 patients who underwent a breast biopsy**]{.hl-yellow}, obtaining 11 variables (one id and 10 scales measured from 1 to 10).

You can see the documentation at <https://vincentarelbundock.github.io/Rdatasets/doc/MASS/biopsy.html>
. . .

1. [**Load the dataset**]{.hl-yellow} from the `{MASS}` package as a tibble

```{r}
#| code-fold: true
library(tidyverse)
biopsy <- as_tibble(MASS::biopsy)
```

---

## 🐣 Case study 3

2. The variable `ID` should be the identifier of each record: [**eliminate duplicates**]{.hl-yellow} for that variable of the previous dataset.

```{r}
#| code-fold: true
biopsy <-
  biopsy |> 
  distinct(ID, .keep_all = TRUE)
```

---

## 🐣 Case study 3

3. From the above dataset [**filter**]{.hl-yellow} only patients with malignant tumor and the variable `V9` with value 4 or lower, [**further deleting any records containing missing data**]{.hl-yellow} in any of the variables.

```{r}
#| code-fold: true
biopsy |> 
  drop_na() |> 
  filter(class == "malignant" & V9 <= 4) 
```


---

## 🐣 Case study 3

4. From the above dataset obtain a [**sample of 20% of the data**]{.hl-yellow} (each record can be chosen with the same probability), and [**sort them**]{.hl-yellow} from highest to lowest by the variable `V1` and, in case of a tie, from lowest to highest by the variable `V2`.


```{r}
#| code-fold: true
set.seed(1234567)
biopsy |> 
  slice_sample(prop = 0.2) |> 
  arrange(desc(V1), V2)
```


---

## 🐣 Case study 4a

From the original starwars dataset, include a column that calculates the BMI. After that, create a new variable that values `NA` if not human, `thin` below 18, `normal` between 18 and 30, `overweight` above 30.

```{r}
#| code-fold: true
starwars |> 
  mutate(height = height / 100,
         BMI = mass / (height^2),
         "human" = case_when(species != "Human" ~ NA,
                             BMI < 18 ~ "thin",
                             BMI < 30 ~ "normal",
                             TRUE ~ "overweight"))
```


---

## 🐣 Case study 4b


Let's proceed to [**create a table with data of voters**]{.hl-yellow} of size `n = 30` where [**simulate the voting intention and their incomes**]{.hl-yellow}


1. Create a `tibble` with two columns, one named `id_voter` and one named `party`. In the first case it should go from 1 to 30. In the second case, it simulates its voting intention so that there is a 0.5 chance of `PP` and 0.5 chance of `SUMAR` (Spanish political parties).

```{r}
#| code-fold: true
data <- 
  tibble("id_voter" = 1:30,
         "party" = sample(c("PP", "SUMAR"), size = 30, replace = TRUE))
```

---

## 🐣 Case study 4b

2. After knowing the voting intention, create a third column called `income` in which you simulate their gross annual income. We will assume that for PP's voters, incomes follows a distribution $N(\mu = 37000€, sigma = 800)$ and that for SUMAR's voters it follows a distribution $N(\mu = 26000€, sigma = 1200)$.

```{r}
#| code-fold: true
data <- 
  data |> 
  mutate("income" =
           rnorm(n = 30, mean = if_else(party == "PP", 37000, 26000),
                 sd = if_else(party == "PP", 800, 1200)))
data
```

---

## 🐣 Case study 5

1. Loads the billboard datatable from the `{tidyr}` package.

```{r}
#| code-fold: true
billboard
```

---

## 🐣 Case study 5

2. First of all, select only the [**first 52 weeks**]{.hl-yellow} (but also artist, track and date variables). After that convert the dataset to [**tidydata**]{.hl-yellow} with the appropriate formats and types for each variable

```{r}
#| code-fold: true
billboard_1 <-
  billboard |> 
  select(artist:date.entered, num_range("wk", 1:52)) |> 
  pivot_longer(cols = "wk1":"wk52", names_to = "week",
               values_to = "rank", names_prefix = "wk",
               values_drop_na = TRUE) |> 
  mutate(week = as.numeric(week))
```

. . .

3. Extracts the [**list of distinct artists**]{.hl-yellow} appearing in the table, including [**how many times**]{.hl-yellow} each appears.

```{r}
#| code-fold: true
billboard_1 |> 
  count(artist)
```

---

## 🐣 Case study 5

4. Determines [**how many songs each artist**]{.hl-yellow} has

```{r}
#| code-fold: true
billboard_1 |> 
  distinct(artist, track) |> 
  count(artist)
```

---

## 🐣 Case study 5

5. Determines the [**5 songs that appear in the charts the most weeks**]{.hl-yellow}. 

```{r}
#| code-fold: true
billboard_1 |> 
  count(track) |>
  slice_max(n = 5, n)
```


---

## 🐣 Case study 5

6. Determines [**for each artist the song that appears the most weeks**]{.hl-yellow}. 

```{r}
#| code-fold: true
billboard_1 |> 
  count(artist, track) |>
  slice_max(n = 1, n, by = artist)
```

---

## 🐣 Case study 5

7. Determines the [**artist with the most songs**]{.hl-yellow} in the list

```{r}
#| code-fold: true
billboard_1 |> 
  distinct(artist, track) |>
  count(artist) |> 
  slice_max(n = 1, n)
```

---

## 🐣 Case study 5

8. Calculates the [**highest position**]{.hl-yellow} that each song has been on. Calculates the highest position an artist has been in.

```{r}
#| code-fold: true
billboard_1 |> 
  slice_min(rank, by = track, with_ties = FALSE) 

billboard_1 |> 
  slice_min(rank, by = artist, with_ties = FALSE) 
```

---

## 🐣 Case study 5

9. Get a [**summary table**]{.hl-yellow} with the average ranking of each artist (counting only the highest ranking achieved by their songs), as well as the number of (different) songs they have placed in the top 100.

```{r}
#| code-fold: true
billboard_1 |> 
  slice_min(rank, by = track, with_ties = FALSE) |> 
  summarise(avg_rank = mean(rank), n_songs = n(), .by = artist)
```

---

## 🐣 Case study 5

10. Perform stratified random sampling, extracting 50% of the data but maintaining the proportion of data among the different quarters.


```{r}
#| code-fold: true
billboard_1 |> 
  mutate(q = lubridate::quarter(date.entered)) |> 
  slice_sample(prop = 0.5, by = q)
```

---



## Import/export

So far we have only used data already loaded in packages but many times [**we will need to import data externally**]{.hl-yellow}. One of the main [**strengths**]{.hl-yellow} of `R` is that we can import data very easily in different formats:


* [**R native formats**]{.hl-yellow}: `.rda`, `.RData` and `.rds` formats.

* [**Rectangular (tabular) data**]{.hl-yellow}: `.csv` and `.tsv` formats

* [**Untabulated data**]{.hl-yellow}: `.txt` format.

* [**Data in excel**]{.hl-yellow}: `.xls` and `.xlsx` formats

* [**Data from SAS/Stata/SPSS**]{.hl-yellow}: `.sas7bdat`, `.sav` and `.dat` formats

* [**Data from Google Drive**]{.hl-yellow}

* [**Data from API's**]{.hl-yellow}: aemet, catastro, twitter, spotify, etc.

---

## R native formats

The [**simplest**]{.hl-yellow} files to import into `R` (and which usually take up less disk space) are its own [**native extensions**]{.hl-yellow}: files in `.RData`, `.rda` and `.rds` formats. To load the former we simply need to [**use the native**]{.hl-yellow} function `load()` by providing it the file path.

* `RData` file: we are going to import a dataset with the different characteristics of the [**Titanic voyagers**]{.hl-purple}, including who survived and who died.


```{r}
#| eval: false
load("./data/titanic.RData")
as_tibble(titanic)
```

```{r}
#| echo: false
library(tidyverse)
load("./data/titanic.RData")
as_tibble(titanic) |> slice(1:5)
```


---

## R native formats

* `.rda` file: we will import a dataset with [**breast cancer data**]{.hl-purple} from [**Royston and Altman (2013)**](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-13-33), including 2982 patients and their characteristics.


```{r}
#| eval: false
load("./data/rotterdam_breast_cancer.rda")
as_tibble(rotterdam)
```

```{r}
#| echo: false
library(tidyverse)
load("./data/rotterdam_breast_cancer.rda")
as_tibble(rotterdam) |> slice(1:7)
```


---

## R native formats

* `.rds` files: for this type we must use `readRDS()`, and we need to incorporate a [**argument `file`**]{.hl-yellow} with the path. In this case we are going to import [**lung cancer data**]{.hl-purple} from the North Central Cancer Treatment Group.

```{r}
#| eval: false
lung_cancer <-
  readRDS(file = "./data/NCCTG_lung_cancer.rds") |> as_tibble()
```

```{r}
#| echo: false
lung_cancer <-
  readRDS(survival::cancer, file = "./data/NCCTG_lung_cancer.rds") |> 
  as_tibble()
lung_cancer |> slice(1:5)
```

::: callout-important

## Important

The [**paths**]{.hl-yellow} must always be [**without spaces, ñ, or accents**]{.hl-yellow}. And note that files loaded with `load()` are automatically loaded into the environment (with the originally saved name), but `read()` functions are only loaded locally (if not saved, they do not exist in the future).

:::

---

## Tabular data: readr

The `{readr}` package within the `{tidyverse}` environment contains several useful functions for [**loading rectangular data (without formatting)**]{.hl-yellow}.

:::: columns
::: {.column width="50%"}

* `read_csv()`: `.csv` files whose [**separator is comma**]{.hl-purple}
* `read_csv2()`: [**semicolon**]{.hl-purple}
* `read_tsv()`: [**tabulator**]{.hl-purple}.
* `read_table()`: [**space**]{.hl-purple}.
* `read_delim()`: generic function for [**character delimited files**]{.hl-purple}.


:::

::: {.column width="50%"}

![](img/data-import-readr.png)
:::
::::

All of them need as **argument the file path** plus **other optional** (skip header or not, decimals, etc). See more at <https://readr.tidyverse.org/>

---

## Tabular data (.csv, .tsv)

The main advantage of `{readr}` is that it [**automates formatting**]{.hl-yellow} to go from a flat (unformatted) file to a tibble (in rows and columns, with formatting).

. . .

* File `.csv`: with `read_csv()` we will load [**comma separated**]{.hl-purple} files, passing as [**argument the path**]{.hl-yellow} in `file = ...`. Let's import the `chickens.csv` dataset (about cartoon chickens, why not). If you look at the output it gives us the type of variables.

```{r}
library(readr)
chickens <- read_csv(file = "./data/chickens.csv")
chickens
```

---

## Tabular data (.csv, .tsv)


The [**variable format**]{.hl-yellow} will normally be done [**automatically**]{.hl-yellow} by `read_csv()`, and we can query it with `spec()`.

```{r}
spec(chickens)
```

---

## Tabular data (.csv, .tsv)

Although it usually does it well automatically we can [**specify the format explicitly**]{.hl-yellow} in `col_types = list()` (in list format, with `col_xxx()` for each type of variable, for example one we will put it as qualitative or factor). We can even indicate that [**variables we want to select**]{.hl-yellow} (without occupying memory), by indicating it in `col_select = ...` (in list format, with `col_select = ...`).


```{r}
chickens <-
  read_csv(file = "./data/chickens.csv",
           col_types = list(col_character(), col_factor(), col_double(), col_character()),
           col_select = c(chicken, sex, eggs_laid))
chickens
```



---


## Untabulated data (.txt)

What happens when the [**separator is not correct**]{.hl-red}?

. . .

If we use `read_csv()` it expects the separator between columns to be a comma but, as you can see with the following `.txt`, it interprets everything as a single column: [**has no comma and does not know where to separate**]{.hl-yellow}

```{r}
datos_txt <- read_csv(file = "./data/massey-rating.txt")
dim(datos_txt)
as_tibble(datos_txt)
```


---

## Untabulated data (.txt)

To do this we have.

* `read_csv2()` when the [**separator is semicolon**]{.hl-yellow}, `read_tsv()` when the [**is a tab**]{.hl-yellow} and `read_table()` when the [**is a space**]{.hl-yellow}.

* `read_delim()` in general.

```{r}
datos_txt <- read_table(file = "./data/massey-rating.txt")
as_tibble(datos_txt)
```


---

## Excel data (.xls, .xlsx)

Another key import package will be the `{readxl}` package for [**importing data from Excel**]{.hl-yellow}. Three functions will be key:

* `read_xls()` specific to `.xls`, `read_xlsx()` specific to `.xlsx`.
* `read_excel()`: for both `.xls` and `.xlsx`.

. . .

We are going to import `deaths.xlsx` with celebrity death records.

```{r}
#| eval: false
library(readxl)
deaths <- read_xlsx(path = "./data/deaths.xlsx")
deaths
```

```{r}
#| echo: false
library(readxl)
deaths <- read_xlsx(path = "./data/deaths.xlsx")
deaths |> slice(1:8)
```

---

## Excel data (.xls, .xlsx)

```{r}
#| eval: false
deaths
```

```{r}
#| echo: false
deaths |> slice(1:8)
```

One thing that is [**very common misfortune**]{.hl-yellow} is that there is some kind of comment or text at the beginning of the file, having to [**skip those rows**]{.hl-yellow}.

---

## Excel data (.xls, .xlsx)

We can [**skip these rows**]{.hl-yellow} directly in the load with `skip = ...` (indicating the number of rows to skip).

```{r}
#| eval: false
library(readxl)
deaths <- read_xlsx(path = "./data/deaths.xlsx", skip = 4)
deaths
```

```{r}
#| echo: false
library(readxl)
deaths <- read_xlsx(path = "./data/deaths.xlsx", skip = 4)
deaths |> slice(1:5)
```

---

## Excel data (.xls, .xlsx)

In addition with `col_names = ...` we can already rename the columns in the import (if [**provide names assumes 1st line already as a data**]{.hl-yellow})

```{r}
#| eval: false
#| code-line-numbers: "3"
deaths <-
  read_xlsx(path = "./data/deaths.xlsx",
            skip = 5,
            col_names = c("name", "profession", "age", "kids", "birth", "death"))
deaths
```

```{r}
#| echo: false
library(readxl)
deaths <- read_xlsx(path = "./data/deaths.xlsx", skip = 5,
                    col_names = c("name", "profession", "age", "kids", "birth", "death"))
deaths |> slice(1:7)
```
        
---

## Excel data (.xls, .xlsx)

Sometimes [**Excel dates are incorrectly formatted**]{.hl-red} (surprise): we can use `convertToDate()` from the `{openxlsx}` package to convert it.


```{r}
#| eval: false
library(openxlsx)
deaths$death <- convertToDate(deaths$death)
deaths
```
   
```{r}
#| echo: false
library(openxlsx)
deaths$death <- convertToDate(deaths$death)
deaths |> slice(1:7)
```

---

## Excel data (.xls, .xlsx)

We can also [**load an Excel with several sheets**]{.hl-yellow}: to [**indicate the sheet**]{.hl-yellow} (either by its name or by its number) we will use the argument `sheet = ...`.

```{r}
#| eval: false
mtcars <- read_xlsx(path = "./data/datasets.xlsx", sheet = "mtcars")
mtcars
```


```{r}
#| echo: false
mtcars <- read_xlsx(path = "./data/datasets.xlsx", sheet = "mtcars")
mtcars |> slice(1:5)
```


. . .
 
We can even indicate the [**range of cells**]{.hl-yellow} to load with `range = ...`.

```{r}
iris <- read_xlsx(path = "./data/datasets.xlsx", sheet = "iris", range = "C1:E4")
iris
```



---

## Importing from SAS/STATA/SPSS

The `{haven}` package within the tidyverse orbit will allow us to [**import files from the 3 most important payment software**]{.hl-yellow}: SAS, SPSS and Stata.

```{r}
library(haven)

# SAS
iris_sas <- read_sas(data_file = "./data/iris.sas7bdat")

# SPSS
iris_spss <- read_sav(file = "./data/iris.sav")

# Stata
iris_stata <- read_dta(file = "./data/iris.dta")
```

---

## Export

In the same way that we can import we can also [**export**]{.hl-yellow}

* exported in `.RData` (recommended option for variables stored in `R`). Remember that this extension [**can only be used in `R`**]{.hl-yellow}. To do so, just use `save(object, file = path)`.

```{r}
table <- tibble("a" = 1:4, "b" = 1:4)
save(table, file = "./data/table.RData")
rm(table) # eliminar
load("./data/table.RData")
table
```


---

## Export

In the same way that we can import we can also [**export**]{.hl-yellow}

* exported in `.csv`. To do this we simply use `write_csv(object, file = path)`.

```{r}
write_csv(table, file = "./data/table.csv")
read_csv(file = "./data/table.csv")
```

---

## Directly from website

One of the main advantages of `R` is that we can make use of all the previous functions of [**import but directly from a web**]{.hl-yellow}, without the need to perform the manual download: instead of passing it the local path we will indicate the [**link**]{.hl-yellow}. For example, we are going to download the covid data from ISCIII (<https://cnecovid.isciii.es/covid19/#documentaci%C3%B3n-y-datos>)

```{r}
#| eval: false
covid_data <-
  read_csv(file = "https://cnecovid.isciii.es/covid19/resources/casos_hosp_uci_def_sexo_edad_provres.csv", n_max = 700)
covid_data
```

---

## Importing from google drive

Another option available (especially if we work with other people working) is to [**import from a Google Drive spreadsheet**]{.hl-yellow}, making use of `read_sheet()` from the `{googlesheets4}` package.

The first time you will be asked for a tidyverse permission to interact with your drive

```{r}
#| eval: false
library(googlesheets4)
google_sheet <-
  read_sheet("https://docs.google.com/spreadsheets/d/1n_UTbD93-oDJR2r-rsMNff5ro147NL_ZN_vYIA2eJ3Q/edit?usp=sharing")
google_sheet
```

---

## Importing from API (owid)

Another interesting option is the [**data download from an API**]{.hl-yellow}: an intermediary between an app or data provider and our `R`. For example, let's load the `{owidR}` library, which allows us to download data from the web <https://ourworldindata.org/>. The `owid_covid()` function loads without realizing it more than 300 000 records with more than 50 variables from 238 countries.

```{r}
#| eval: false
library(owidR)
owid_covid()
```

```{r}
#| echo: false
#| eval: false
library(owidR)
owid_covid() |> slice(1:5)
```

---

## Importing from (owid)

This package has the `owid_search()` function to search datasets by keywords, for example, `emissions`, giving us a dataset with the title of the database and its id for later use.

```{r}
#| eval: false
as_tibble(owid_search("emissions"))
```

```{r}
#| echo: false
#| eval: false
as_tibble(owid_search("emissions")) |> slice(1:4)
```

. . .

Let's ask you for example for the [**oecd emissions**]{.hl-yellow}

```{r}
#| eval: false
owid("emissions-of-air-pollutants-oecd")
```

```{r}
#| echo: false
#| eval: false
owid("emissions-of-air-pollutants-oecd") |> slice(1:5)
```

---

## Importing from API (aemet)

In many occasions to connect to the API we will first have to [**register and obtain a key**]{.hl-yellow}, this is the case of the `{climaemet}` package to access meteorological data (<https://opendata.aemet.es/centrodedescargas/inicio>).


Once we have the API key we register it in our RStudio to be able to use it in the future.


```{r}
#| eval: false
library(climaemet)

# Api key
apikey <- "eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqYXZhbHYwOUB1Y20uZXMiLCJqdGkiOiI4YTU1ODUxMS01MTE3LTQ4MTYtYmM4OS1hYmVkNDhiODBkYzkiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTY2NjQ2OTcxNSwidXNlcklkIjoiOGE1NTg1MTEtNTExNy00ODE2LWJjODktYWJlZDQ4YjgwZGM5Iiwicm9sZSI6IiJ9.HEMR77lZy2ASjmOxJa8ppx2J8Za1IViurMX3p1reVBU"

aemet_api_key(apikey, install = TRUE)
```


```{r}
#| echo: false
library(climaemet)
```

--- 

## Importing from (aemet)


With this package we can do a [**search for stations**]{.hl-yellow} to know both its postal code and its identifier code within the AEMET network (for example, the station of the airport of El Prat, Barcelona, is the code `"0076"`).

```{r}
#| eval: false
stations <- aemet_stations()
stations
```

```{r}
#| echo: false
#| eval: false
stations <- aemet_stations()
stations |> slice(1:4)
```

```{r}
#| eval: false
aemet_last_obs("0076")
```

```{r}
#| echo: false
#| eval: false
aemet_last_obs("0076") |> slice(1:4)
```

---


## 💻 Your turn {#tu-turno-6}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset
### [**Exercise 1**]{.hl-yellow}

📝 The `who` dataset we have used in previous exercises, export it to a native `R` format in the `data` folder of the project

```{r}
#| code-fold: true
#| eval: false
library(tidyr)
save(who, file = "./data/who.RData")
```

### [**Exercise 2**]{.hl-yellow}

📝 Loads the `who` dataset but from the data folder (import the file created in the previous exercise)

```{r}
#| code-fold: true
#| eval: false
load("./data/who.RData")
```

### [**Exercise 3**]{.hl-yellow}

📝 Repeats the same (export and import) in 4 formats: `.csv`, `.xlsx`, `.sav` (spss) and `.dta` (stata)

```{r}
#| code-fold: true
#| eval: false

# csv
library(readr)
write_csv(who, file = "./data/who.csv")
who_data <- read_csv(file = "./data/who.csv")

# excel
library(openxlsx)
write.xlsx(who, file = "./data/who.xlsx")
who_data <- read_xlsx(path = "./data/who.xlsx")

# sas y stata
library(haven)
write_sav(who, path = "./data/who.sav")
who_data <- read_spss(path = "./data/who.sav")

write_dta(who, path = "./data/who.dta")
who_data <- read_dta(path = "./data/who.dta")
```

### [**Exercise 4**]{.hl-yellow}

📝 Repeat the loading of `who.csv` but only select the first 4 columns already in the load.

```{r}
#| code-fold: true
#| eval: false
who_select <-
  read_csv(file = "./data/who.csv",
           col_select = c("country", "iso2", "iso3", "year"))
```


:::

---

## 🐣 Case study 6 {#case-6}


In the data folder you have the dataset `breast-cancer-wisconsin-data.csv`. Create a `.qmd` file and customize it to include the following:

1. Import the csv file into a `tibble`. Is it tidydata? How many patients and variables do we have?

. . .

2. The dataset represents breast cancer data (`id` identifier, `diagnosis` the malignant/benign diagnosis and all other tumor properties). What % had a malignant tumor and what % a benign one?

. . .

3. Which of the two types of tumors have, on average, a higher radius? 


---

## 🐣 Case study 6


4. Seek the help of the `t.test()` function. This function allows us to test whether or not the means of two distributions are equal. Can we reject the null hypothesis that the radius means are the same, under a significance of $alpha = 0.05$?


# Lesson 7: functions {#clase-7}

[**Functions**]{style="color:#444442;"}

---

## Summary

Let's make a brief summary of what we have learned up to now

. . .

* [**Lesson 1**]{.hl-yellow}: main concepts about how R works (operating with vectors)

. . .

* [**Lesson 2**]{.hl-yellow}: how to store data (first databases and tidy data)

. . .

* [**Lesson 3**]{.hl-yellow}: first operations by rows with tidyverse (filter, slice_max, slice_min, slice, slice_sample, drop_na, arrange, distinct)

. . .

* [**Lesson 4**]{.hl-yellow}: first operations by columns with tidyverse (select, relocate, mutate)

. . .

* [**Lesson 5**]{.hl-yellow}: generating first summaries (count, group_by, summarise) and reports (Quarto)

. . .

* [**Lesson 6**]{.hl-yellow}: import/export files (load, read_csv, read_xlsx, save, write_csv, write_xls, write_xlsx)

---

## Functions

Not only can we use **default functions** that come already loaded in packages, we can also [**create our own functions**]{.hl-yellow} to **automate tasks**.

How to [**create our own function**]{.hl-purple}? Let's take a look at its **basic scheme**:

. . .

* [**Name**]{.hl-yellow}: for example `name_fun` (no spaces or strange characters). To the name we [**assign the reserved word**]{.hl-yellow} `function()` .

. . .

* Define [**input arguments**]{.hl-yellow} (inside `function()`).

. . .

```{r}
#| eval: false
name_fun <- function(input1, input2, ...) {
  
}
```

---

## Functions

Not only can we use **default functions** that come already loaded in packages, we can also [**create our own functions**]{.hl-yellow} to **automate tasks**.

How to [**create our own function**]{.hl-purple}? Let's look at its **basic scheme**:


* [**Body**]{.hl-yellow} function inside `{ }`.

. . .

* We end the function with the [**output**]{.hl-yellow} arguments with `return()`.


```{r}
#| eval: false
name_fun <- function(input1, input2, ...) {
  
  # Code
  code
  
  # Output
  return(var_output)
}
```


---

## Functions

* `input1, input2, ...`: will be the [**input arguments**]{.hl-yellow}, the arguments that the function takes to execute the code inside it.

* `code`: lines of code that we want to [**execute the function**]{.hl-yellow}. 

* `return(var_output)`: the [**output arguments**]{.hl-yellow} will be entered.


```{r}
#| eval: false
name_fun <- function(input1, input2, ...) {
  
  # Code
  code
  
  # Output
  return(var_output)
}
```

::: callout-important
## Important

All variables that we define inside the function are [**local variables: they will only exist inside the function**]{.hl-yellow} unless we specify otherwise.

:::

---

## Functions

Let's look at a very simple example of a function for [**calculate the area of a rectangle**]{.hl-yellow}.

. . .

Since the area of a rectangle is calculated as the **product of its sides**, we will need just that, its sides: those will be the [**input arguments**]{.hl-yellow} and the [**value to return**]{.hl-purple} will be just its **area** ($side_1 * side_2$).

. . .

```{r}
# Definition
calc_area <- function(side_1, side_2) {
  
  area <- side_1 * side_2
  return(area)
  
}
```

---

## Functions


We can also do a direct definition, **without storing variables along the way**.

```{r}
# Definition
calc_area <- function(side_1, side_2) {
  
  return(side_1 * side_2)
  
}
```


[**How to apply the function?**]{.hl-yellow}

```{r}
calc_area(5, 3) # rectangle 5 x 3 
calc_area(1, 5) # rectangle 1 x 5
```

---

## Default inputs

Imagine now that we realize that 90% of the time we use this function to [**default calculate the area of a square**]{.hl-yellow} (i.e. we only need one side). To do this, we can define [**default arguments**]{.hl-yellow} in the function: they will take that value unless we assign another one.

Why not assign `side_2 = side_1` by default, to save lines of code and time?

. . .

```{r}
calc_area <- function(side_1, side_2 = side_1) {
  
  # Code
  area <- side_1 * side_2
  
  # Result
  return(area)
  
}
```

---

## Default inputs


```{r}
calc_area <- function(side_1, side_2 = side_1) {
  
  # Code
  area <- side_1 * side_2
  
  # Result
  return(area)
  
}
```

Now [**default**]{.hl-yellow} the second side will be equal to the first (if added it will use both).


```{r}
calc_area(side_1 = 5) # square
calc_area(side_1 = 5, side_2 = 7) # rectangle
```

---
 
## Multiple output

Let's complicate the function a bit and add in the output the values of each side, labeled `side_1` and `side_2`, [**packing the output in a list**]{.hl-yellow}.

```{r}
# Definition
calc_area <- function(side_1, side_2 = side_1) {
  
  # Code
  area <- side_1 * side_2
  # Result
  return(list("area" = area, "side_1" = side_1, "side_2" = side_2))
  
}
```


::: callout-important
## Important

All the variables that we define inside the function are [**local variables: they will only exist inside**]{.hl-yellow}

:::

---

## Introduction to lists

Let's see a small summary of the data we already know:

* [**vectors**]{.hl-yellow}: collection of elements of the same type. They can be numbers, characters or logical values, among others.

* [**matrices**]{.hl-yellow}: BIDIMENSIONAL collection of elements of equal type and equal length.

* [**data.frame / tibble**]{.hl-yellow}: BIDIMENSIONAL collection of elements of equal length but of any type.

. . .

The [**lists**]{.hl-yellow} will be [**collections of variables of different type and different length**]{.hl-purple}, with totally heterogeneous structures (even a list can have inside it another list).

---

## Introduction to lists


Let's create [**our first list**]{.hl-yellow} with `list()` with three elements: our parents' names, our place of birth and our siblings' ages.

```{r}
var_1 <- c("Paloma", "Gregorio")
var_2 <- "Madrid"
var_3 <- c(25, 30, 26)

list_example <-
  list("parents" = var_1, "birth_place" = var_2,
       "siblings_ages" = var_3)
list_example
```

---

## Introduction to lists

```{r}
length(list_example)
```

If you look at the object we have defined as a list, its [**length**]{.hl-yellow} is 3 because we have **stored three elements**: a vector of characters (of length 2), a character (vector of length 1), and a vector of numbers (of length 3).

. . .

We have stored elements of [**different type**]{.hl-yellow} (something we could already do) but, in addition, of **different lengths**.

```{r}
dim(list_example) # NULL since we do not have a bidim object
class(list_example) # list
```

---

## Introduction to lists

If we put them together with a `tibble()`, since they have different lengths, we would get an [**error**]{.hl-red}.

```{r}
#| error: true
library(tibble)
tibble("parents" = var_1,
       "birth_place" = var_2,
       "siblings_ages" = var_3)
```

---


## Introduction to lists

* [**Access by index**]{.hl-yellow}: with the operator `[[i]]` we access the **i-th element** of the list.

```{r}
list_example[[1]]
```

. . .

* [**Access by name**]{.hl-yellow}: with the operator `$element_name` we access by its name.

```{r}
list_example$parents
```

. . .

In contrast, the [**single bracket**]{.hl-yellow} allows us to access [**several elements**]{.hl-yellow} at a time

```{r}
# Many elements
list_example[1:2]
```

---

## Multiple output

Before, we did not care about the order of the arguments, but now the [**order of the input arguments matters**]{.hl-yellow}, since we include `side_1` and `side_2` in the output. 

. . .

::: callout-note
## Tip

It is highly recommended to make the function call [**explicitly stating the arguments**]{.hl-yellow} to improve **legibility and interpretability**.

```{r}
# Same as calc_area(5, 3)
calc_area(side_1 = 5, side_2 = 3)
```

:::

---

## Own functions: knowledge

It seems silly what we have done, but we have crossed an important frontier: we have gone from [**consuming knowledge**]{.hl-yellow} (code from other packages, elaborated by others), to [**generating knowledge**]{.hl-purple}, creating our own functions.


---

## Local vs global variables

An important aspect to think about with functions: what happens if we [**name a variable inside**]{.hl-yellow} a function to which we have **forgotten to assign** a value inside?

. . .

We must be cautious when using functions in `R`, since due to the [**"lexicographic rule "**]{.hl-yellow}, if a variable is not defined inside the function, `R` will [**look for such a variable in the environment**]{.hl-purple} of variables.

```{r}
x <- 1
fun_example <- function() {
    
  print(x) # No output
}
fun_example()
```

---

## Local vs global variables

If a variable [**is already defined outside the function (global environment)**]{.hl-yellow}, and is also used inside changing its value, the value [**only changes inside**]{.hl-yellow} but [**not in the global environment**]{.hl-red}.

```{r}
x <- 1
fun_example <- function() {
    
  x <- 2
  print(x) # what is assigned inside
}
```

```{r}
# what is assigned inside
fun_example() #<<
# what is assigned outside
print(x) #<<
```

---

## Local vs global variables


If we want it to change locally as well as [**globally**]{.hl-yellow} we must use the [**double assignment**]{.hl-yellow} (`<<-`).

```{r}
x <- 1
y <- 2
fun_example <- function() {
  
  # change locally
  x <- 3 
  # change globally
  y <<- 0 #<<
  
  print(x)
  print(y)
}

fun_example() # what is assigned inside
x # what is assigned outside
y # what is assigned outside
```

---


## 💻 Your turn {#tu-turno-7b}

[**Try to solve the following exercises without looking at the solutions**]{style="color:#444442;"}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Modify the code below to define a function called `sum_fun`, so that given two elements, it returns their sum.

```{r}
#| eval: false
name_fun <- function(x, y) {
  sum <- # código a ejecutar
  return()
}
sum_fun(3, 7)
```

```{r}
#| code-fold: true
#| eval: false
sum_fun <- function(x, y) {
  sum <- x + y
  return(sum)
}
sum_fun(3, 7)
```

### [**Exercise 2**]{.hl-yellow}

📝 Modify the code below to define a function called `product_fun`, so that given two elements, it returns their product, but by default it calculates the square

```{r}
#| eval: false
name_fun <- function(x, y) {
  product <- # code
  return()
}
product_fun(3)
product_fun(3, -7)
```

```{r}
#| code-fold: true
#| eval: false
product_fun <- function(x, y = x) {
  product <- x * y
  return(product)
}
product_fun(3)
product_fun(3, -7)
```

### [**Exercise 3**]{.hl-yellow}

📝 Define a function called `equal_names` that, given two names, tells us if they are equal or not. Do this by considering case-sensitive, and case-insensitive. Take a look at the `{stringr}` package.

```{r}
#| code-fold: true
#| eval: false
# Case-sensitive
equal_names <- function(p_1, p_2) {
  return(p_1 == p_2)
}
equal_names("Javi", "javi")
equal_names("Javi", "Lucía")

equal_names <- function(p_1, p_2) {
  return(toupper(p_1) == toupper(p_2))
}
equal_names("Javi", "javi")
equal_names("Javi", "Lucía")
```

### [**Exercise 4**]{.hl-yellow}

📝 Create a function called `BMI_calc` that, given two arguments (weight and height in meters) and a name, returns a list with the BMI and the name.

```{r}
#| code-fold: true
#| eval: false
BMI_calc <- function(names, w, h) {
  
  return(list("names" = names, "BMI" = w/(h^2)))
}
```

### [**Exercise 5**]{.hl-yellow}

📝 Repeat the above exercise but with another optional argument called units (by default, `units = "m"`). Develop the function so that it does the right thing if `units = "m"` and if `units = "cm"`.

```{r}
#| code-fold: true
#| eval: false
BMI_calc <- function(names, w, h, units = "m") {
  
  return(list("names" = names,
              "BMI" = w/(if_else(units == "m", h, h/100)^2)))
}
```

 
### [**Exercise 6**]{.hl-yellow}

📝 Create a tibble of 7 persons, with three variables (invent name, and simulate weight, height in centimeters), and apply the defined function so that we obtain a fourth column with their BMI.

```{r}
#| code-fold: true
#| eval: false
data <-
  tibble("names" = c("javi", "sandra", "laura",
                       "ana", "carlos", "leo", NA),
         "w" = rnorm(n = 7, mean = 70, sd = 1),
         "h" = rnorm(n = 7, mean = 168, sd = 5))

BMI |> 
  mutate(BMI = BMI_calc(names, w, h, units = "cm")$BMI)
```


:::


---

## 🐣 Case study 7: functions {#case-7-b}

Define a function called `temperature_converter` that, given a temperature in Fahrenheit, Celsius or Kelvin, converts it to any of the others (think what arguments the user needs). Apply the function to the `Temp` column of the `airquality` set, and incorporate it into the file in a new `Temp_Celsius` column.


# Lesson 8: flow control structures {#clase-8}

[**Flow control structures**]{style="color:#444442;"}

---


## Flow control structures

A [**control expression**]{.hl-yellow} will be a set of commands that allow us to [**decide the path**]{.hl-yellow} along which we want our code to progress:

* What do we do if A happens?

* What if B happens?

* Do I have to program X times the same thing if you want it to repeat?

. . .

If you have programmed in any other language, you will be familiar with [**conditional structures**]{.hl-yellow} such as an `if (blabla) {...} else {...}` (which we will sometimes use) or [**loops**]{.hl-yellow} `for/while` (which we will try to avoid as much as possible).

---

## If structures

One of the most famous control structures of any programming language is the [**conditional structure**]{.hl-yellow} `if`.

> IF the imposed conditions are fulfilled (TRUE), it executes the commands we have inside it.

For example, the structure `if (x == 1) { code A }` will [**execute the code between braces**]{.hl-yellow} but [**IF AND ONLY IF**]{.hl-purple} the [**condition is true**]{.hl-purple} (in this case, only if `x` equals 1). Otherwise, it does nothing.

. . .

Let's define for example a simple variable, the ages of 8 people and let's check which of them are minors.

```{r}
ages <- c(14, 17, 24, 56, 31, 20, 87, 73)
ages < 18
```

---

## If structures


Remember that with the `any()` and `all()` functions we can know if [**all or any of the elements**]{.hl-yellow} of a vector fulfill a condition.

```{r}
any(ages < 18) 
```

. . .

We are going to build our first conditional structure: we want that, [**If there is a minor, print us a message**]{.hl-yellow}.

```{r}
if (any(ages < 18)) { 
  
  print("There is any person of legal age")
  
}
```

---

## If structures

```{r}
#| eval: false
if (any(ages < 18)) { 
  
  print("There is any person of legal age")
  
}
```


In case [**conditions are not verified**]{.hl-yellow} inside the `if()` (return `FALSE`), nothing will happen. 


```{r}
if (all(ages >= 18)) { 
  
  print("Everyone is of legal age")
  
}
```

Notice that in this case **we have not obtained any message** because the condition `all(ages >= 18)` is not `TRUE` (they are not all older than 18), so **it has not executed the code**.

---

## If-else structures

The `if (condition) { }` structure can be combined with an `else { }`: when the [**condition is not verified**]{.hl-yellow} (as before), it will [**execute the alternative code**]{.hl-yellow} inside the `else { }`, allowing us to decide what happens when it IS verified and when it IS NOT.

. . .

For example, the structure `if (x == 1) { code A } else { code B }` will execute A if `x` is 1 and B in any other case.

```{r}
if (all(ages >= 18)) { 
  
  print("Everyone is of legal age")
  
} else {
  
  print("There is any person under legal age")
}
```

---

## If-else structures

This `if - else` structure can be [**nested**]{.hl-yellow}: imagine that we want to perform an action if all were of legal age; otherwise, but if all minors are 16 or older, perform another action; otherwise, another action.

```{r}
if (all(ages >= 18)) { 
  
  print("Everyone is of legal age")
  
} else if (all(ages >= 16)) {
  
  print("There are some minors but all are 16 years of age or older")
  
} else { print("There is any person under 16 years of age") }
```

::: callout-note
## Tip

You can **collapse the control structures** by clicking on the arrow to the left of them in your script.

:::


---

## If-else vectorized structures


This conditional structure can be [**vectorized**]{.hl-yellow}: gather in a single row a large number of comparison structures with the function `if_else()` (`{dplyr}` package), whose input arguments will be

* the condition to evaluate
* what happens when it is met
* what happens when it is not met

With the example of the ages, we are going to leave the data absent if they are under age, and if they are over age it stays as it is.

```{r}
library(dplyr)
if_else(ages >= 18, ages, NA)
```

---

## If-else vectorized structures


All these structures [**not only for numeric data**]{.hl-yellow}. We are going to define a vector of names with some absent ones, and we are going to replace the absent ones by the text `"unknown_name"` (the ones that are not absent, that is to say the ones that `is.na()` returns FALSE, stay as they are).

```{r}
names <- c("Juan", "María", NA, NA, "Lucía",
           "Carmen", "Javier", NA, "Carlos", 
           NA, "Gregorio", "Paloma")

if_else(is.na(names), "unknown_name", names)
```

---

## If-else vectorized structures


It is important to remember that a logical condition actually has [**three possible outcomes**]{.hl-yellow}: `TRUE`, `FALSE` and `NA` (missing values). What happens when the [**evaluated condition produces a missing data**]{.hl-purple}?

```{r}
ages <- c(NA, ages, NA)
if_else(ages > 18, "greater than 18", "otherwise")
```

. . .


The `if_else()` function provides us with an extra argument `missing = ...` to decide the value to be assigned for missing values (by default, it returns `NA`).

```{r}
if_else(ages > 18, "greater than 18", "otherwise", missing = "unknown")
```


---

## Loops

Although most of the time they can be replaced by other more readable and efficient expressions, it is important to know another well-known control expression: [**loops**]{.hl-yellow}.

* `for { }`: allows [**repeating the same code**]{.hl-yellow} a [**fixed and known number**]{.hl-purple} of times (usually based on an index).

* `while { }`: allows [**repeating the same code**]{.hl-yellow} a [**indeterminate number of times**]{.hl-purple}, until a given **condition** is no longer met.

---

## For loops

A [**for-loop**]{.hl-yellow} is a structure that allows us to [**repeat**]{.hl-yellow} a set of commands a [**finite and known number**]{.hl-purple} of times: given a **set of indices**, the loop will loop through each of them.

. . .

We are going to define a vector `x` any and print each element squared: if we wanted the first element squared we would write `x[1]^2`, if we wanted to do it in general, for the i-th element, `x[i]^2`. What we will do inside the `for (indices) { code }` is to indicate which values `i` will take ([**index vector**]{.hl-yellow}).

```{r}
x <- c(0, -7, 1, 4)
for (i in 1:4) {
  
  print(x[i]^2)
  
}
```

---

## For loops

```{r}
#| eval: false
for (i in 1:4) { 
  print(x[i]^2) 
}
```

Inside the parentheses `for ()` we have just a [**sequence of numbers**]{.hl-yellow} that we have learned to construct. If we wanted it to do the same but excluding for example the second element it would be enough to define the indexes to traverse as `c(1, 3, 4)`.

```{r}
for (i in c(1, 3, 4)) {
  
  print(x[i]^2)
  
}
```

---

## For loops

We can also define a variable `y <- rep(0, 4)` (an "empty" **vector** filled with zeros), storing the [**i-th element of the vector**]{.hl-yellow} defined as `x[i]^2`.

```{r}
y <- rep(0, 4)
for (i in 1:4) {
  
  y[i] <- x[i]^2
  
}
y
```

. . .

The above is equivalent to this

```{r}
y <- x^2
y
```

---

## Avoiding loops


Using the `{microbenchmark}` package we can see how [**loops are less efficient**]{.hl-yellow} (hence most of the time we try to avoid them if there is an alternative).

```{r}
library(microbenchmark)
x <- 1:1000
microbenchmark(y <- x^2, 
               for (i in 1:100) { y[i] <- x[i]^2 },
               times = 500)
```

---
 
## For loops


Let's look at another example [**combining numeric and character vectors**]{.hl-yellow}: let's define again a vector of ages and names, and let's go through each one printing a message on the screen.

```{r}
names <- c("Javi", "Laura", "Carlos", "Lucía", "Mar")
ages <- c(33, 51, 18, 43, 29)

for (i in 1:5) { 
  
  print(glue("{names[i]} are {ages[i]} years old")) 
  
}
```

---

## For loops


Notice that [**if we don't want to worry about adding another person**]{.hl-yellow}, we can make the loop start at 1 and end at the [**last place**]{.hl-yellow} (whichever one it is), using `length()`.

```{r}
for (i in 1:length(names)) { 
  
  print(glue("{names[i]} are {ages[i]} years old")) 
  
}
```

---

## For loops

Although the set that the loop runs through is usually numeric indices, we can [**run through any type of object**]{.hl-yellow}, for example days of the week

```{r}
library(stringr)
week_days <- c("monday", "tuesday", "wednesday", "thursday",
               "friday", "saturday", "sunday")

for (days in week_days) {
  
  print(str_to_upper(days))
}
```

---

## For loops

One last example: let's go through our `swiss` dataset from the `{datasets}` package and we will **pass to missing data** all the fertility values greater than 80.

```{r}
for (i in 1:nrow(swiss)) {
  
  if (swiss$Fertility[i] > 80) { 
    
    swiss$Fertility[i] <- NA
    
  }
}
```

. . .

This would be exactly equivalent to the `if_else()` vectorized `if_else()` we saw previously

```{r}
data("swiss")
swiss$Fertility <- if_else(swiss$Fertility > 80, NA, swiss$Fertility)
```


---

## While loops

Another way to design a loop is with the `while { }` structure, which will execute the loop an [**unknown a priori number of times**]{.hl-yellow}, it will do so until the [**imposed condition is no longer true**]{.hl-yellow}. For example, we will initialize a variable `cycles <- 1`, and at each step we will increment by one unit, and we will not exit the loop until `cycles > 4`.

```{r}
cycles <- 1
while(cycles <= 4) {
  
  print(glue("Not yet, cycles {cycles}")) 
  cycles <- cycles + 1
  
}
```


---
  
## While loops


And what happens when the [**condition never becomes FALSE**]{.hl-yellow}? See for yourself.

```{r}
#| eval: false
while (1 > 0) {
  
  print("Press ESC to abort the loop")
  
}
```

&nbsp;

::: callout-warning
## Warning

A `while { }` loop can be very dangerous if it is not well controlled that the loop ends at some point.

:::

---

## While loops

We have two commands reserved to be able to [**abort a loop or forcibly advance**]{.hl-yellow}:

* `break`: enables you to [**stop a loop**]{.hl-yellow} even if it has not reached the end of its index set to traverse (or the condition is still met).

```{r}
for(i in 1:10) {
  if (i == 3) {
    
    break # if i = 3, stop the loop
    
  }
  print(i)
}
```

---

## While loops

We have two commands reserved to be able to [**abort a loop or forcibly advance**]{.hl-yellow}:

* `next`: [**forces the loop to advance**]{.hl-yellow} to the next iteration, aborting the current iteration it is in. 

```{r}
for(i in 1:5) {
  if (i == 3) {
    
    next # if i = 3, we continue
    
  }
  print(i)
}
```

---

## Repeat loops

Although it is a rarely used option, there is a control structure called `repeat { }` that executes a [**loop infinitely until we order it to stop**]{.hl-yellow} with a break.

```{r}
count <- 0
repeat { 
  
  count <- count + 1
  if (count >= 100) { break }
  
}
count
```


---

## Replicate

Another way to [**repeat or replicate**]{.hl-yellow} code, apart from the loop structures already seen, is to make use of `replicate()`, which for the moment we will not make it depend on an index: we will simply [**repeat n times**]{.hl-yellow} the same code.

```{r}
x <- 1:3
replicate(n = 3, x^2)
```

---

## 💻 Your turn {#tu-turno-7}

::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Modify the code below to print a message on the screen if all data in the `airquality` set are from months other than January.

```{r}
#| eval: false
library(datasets)
months <- airquality$Month

if (months == 2) {
  print("No data for the month of January")
}
```

```{r}
#| code-fold: true
#| eval: false
library(datasets)
months <- airquality$Month

if (all(months != 1)) {
  print("No data for the month of January")
}
```


### [**Exercise 2**]{.hl-yellow}

📝 Modify the code below to store in a variable called `high_temperature` a `TRUE` value if any of the records have a temperature greater than 90 (they are in Farenheit) and a `FALSE` otherwise.
 
```{r}
#| eval: false
temp<- airquality$Temp

if (temp == 100) {
  print("Some of the records have temperatures above 90 Farenheit.")
}
```

 
```{r}
#| eval: false
#| code-fold: true
# Option 1
temp <- airquality$Temp
high_temp <- FALSE
if (any(temp > 90)) {
   high_temp <- TRUE
}

# Option 2
high_temp <- any(airquality$Temp > 90)
```

### [**Exercise 3**]{.hl-yellow}

📝 Modify the code below to design a `for` loop of 5 iterations that loops through the first 5 odd ones and adds one to them.

```{r}
#| eval: false
for (i in 1:5) {
  
  print(i)
}
```

```{r}
#| eval: false
#| code-fold: true
for (i in c(1, 3, 5, 7, 9)) {
  
  print(i + 1)
}
```

### [**Exercise 4**]{.hl-yellow}

📝 Modify the code below to design a `while` loop that starts with a `count <- 1` variable and stops when it reaches 6.

```{r}
#| eval: false
count <- 1
while (count == 2) {
  
  print(count)
}
```

```{r}
#| eval: false
#| code-fold: true
count <- 1
while (count < 6) {
  
  print(count)
  count <- count + 1
  
}
```


### [**Exercise 5**]{.hl-yellow}

📝 Using `sample()`, it simulates the roll of 100 dice (each with 6 sides), but in such a way that the die is tricked, and calculates the average of the rolls.


```{r}
#| eval: false
#| code-fold: true

# no tricked
rolls <- sample(x = 1:6, size = 100, replace = TRUE)
mean(rolls)

# tricked
rolls <-
  sample(x = 1:6, size = 100, replace = TRUE,
         prob = c(1/2, 1/10, 1/10, 1/10, 1/10, 1/10))
mean(rolls)
```

:::

---


## 🐣 Case study 8 {#case-8}


📝 Design a `for` loop of 200 iterations that, starting at an initial value of 100 (euros), adds 3€ (updating the value) if the current number of the iteration is even, and subtracts 5€ if it is odd (investigate the `%%` function).

```{r}
10 %% 2
11 %% 2
12 %% 2
13 %% 2
```


. . .

📝 Design the above loop but store the money from each iteration in some variable

. . .


📝 Design the loop of exercise 5 but stop when we have no money left.

---

## Quali: factors

In statistics, when we talk about [**qualitative variables**]{.hl-yellow}, we will call **levels or modalities** the **different values** that these data can take. For example, in the case of the `sex` variable of the `starwars` set, we have 4 allowed levels: `female`, `hermaphroditic`, `male` and `none` (in addition to missing data).

```{r}
starwars |> count(sex)
```



---

## Quali: factors

These kinds of variables are known in `R` as [**factors**]{.hl-yellow}, and the fundamental package to deal with them is `{forcats}` (from the `{tidyverse}` environment). 


![](img/factors.jpg)


---

## Quali: factors

This package allows us to set the [**levels**]{.hl-yellow} (stored internally as `levels`) that a given categorical variable takes so that no mistakes, errors in data collection and generation can be generated. It also makes their analysis less computationally expensive when doing searches and comparisons, giving them a [**different treatment than normal text strings**]{.hl-yellow}.

. . .

Let's see a simple example simulating a `party` variable taking the values `"PP"`, `"PSOE"` and `"SUMAR"` (of size 15)

```{r}
set.seed(1234567)
party <- sample(x = c("PP", "PSOE", "SUMAR"), size = 15, replace = TRUE)
party
```

The `party` variable is currently of [**type text**]{.hl-yellow}, of type `chr`, something we can check with `class(state)`.

```{r}
class(party)
```

---

## Quali: factors

From a statistical and computational point of view, for `R` this variable right now would be equivalent to a named variable. But statistically [**a variable as a string**]{.hl-yellow} is not the same as a categorical variable that [**can only take those 3 levels**]{.hl-yellow}. How to [**convert to factor**]{.hl-yellow}? 

. . .

By making use of the `as_factor()` function from the `{forcats}` package.

```{r}
library(tidyverse)
party_fct <- tibble("id" = 1:length(party),
                    "party" = as_factor(party))
party_fct
```

---

## Quali: factors

Not only the class of the variable  has  changed, but now, below the saved value, the sentence `Levels: ...` appears: these are the [**modalities or levels**]{.hl-yellow} of our qualitative. 

```{r}
party_fct |> pull(party)
```

---


## Quali: factors

Imagine that we are defining the database of deputies of the Congress and that the deputies of the PP did not attend that day to the plenary session: although our variable does not take that value THAT DAY, the state `PSOE` is a [**allowed level in the database**]{.hl-yellow} (so even if we eliminate it, because it is a factor, the level remains, we do not have it now but it is an allowed level).


```{r}
party_fct |> 
  filter(party %in% c("PP", "SUMAR")) |> 
  pull(party)
```

---

## Quali: factors

With `factor()` function we can [**explicitly specify**]{.hl-yellow} the names of the modalities and using `levels = ...` we can explicitly tell it the [**"order" of the modalities**]{.hl-yellow} 


```{r}
party_fct <-
  tibble(id = 1:length(party),
         party = factor(party, levels = c("SUMAR", "PP", "PSOE")))
party_fct |> pull(party)
```


---


## Quali: factors

The previous "order" is just in the sense which it will be counted/plotted first) but [**we don't have (yet) an ordinal variable**]{.hl-purple}


```{r}
party_fct$party < "SUMAR"
```

. . .

What if we want to [**define a qualitative variable ORDINAL**]{.hl-yellow}? Inside `factor()` we must indicate that `ordered = TRUE`.

```{r}
marks <- c("A", "E", "F", "B", "A+", "A", "C", "C", "D", "B", "A", "C", "C", "E", "F", "D", "A+")
marks_database <-
  tibble("student" = 1:length(marks),
         "marks" =
           factor(marks, levels = c("F", "E", "D", "C", "B", "A", "A+"),
                  ordered = TRUE))
marks_database |> pull(marks)
```

---

## Quali: factors

What changes? If you notice now, although the variable is still qualitative, we can [**make comparisons and order the records**]{.hl-yellow} because there is a [**hierarchy**]{.hl-purple} between the modalities.

```{r}
marks_database |> filter(marks >= "B")
```

---

## Quali: factors


:::: columns
::: {.column width="45%"}

If we want to tell it to [**drop an unused level**]{.hl-yellow} at that moment (and that we want to [**exclude from the definition**]{.hl-purple}) we can do it with `fct_drop()`.

```{r}
marks_database |> 
  filter(marks %in% c("F", "E", "D", "C", "B", "A")) |> 
  pull(marks)
```

:::

::: {.column width="55%"}


```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/drop_factor.jpg")
``` 

:::

::::

```{r}
marks_database |> 
  filter(marks %in% c("F", "E", "D", "C", "B", "A")) |> 
  mutate(marks = fct_drop(marks)) |>  
  pull(marks)
```

---

## Quali: factors


:::: columns
::: {.column width="45%"}


Just as we can delete levels we can [**expand existing levels**]{.hl-yellow} (even if there is no data for that level at that time) with `fct_expand()`.

:::

::: {.column width="55%"}


```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factor_expand.jpg")
``` 

:::
::::

```{r}
marks_database |> 
  mutate(marks = fct_expand(marks, c("F-", "A+", "A++"))) %>% 
  pull(marks)
```

---

## Quali: factors

:::: columns
::: {.column width="45%"}

In addition with `fct_explicit_na()` we can [**assign a level to the missing values**]{.hl-yellow} to be included in the analysis and visualizations.

:::

::: {.column width="55%"}


```{r echo = FALSE,  out.width = "100%", fig.align = "left"}
knitr::include_graphics("./img/factor_explicit.jpg")
``` 

:::
::::

```{r}
fct_explicit_na(factor(c("a", "b", NA)))
```

---

## Quali: factors

Even once defined we can [**reorder the levels**]{.hl-yellow} with `fct_relevel()`.


```{r}
marks_database_expand <- 
  marks_database |>  
  mutate(marks = fct_expand(marks, c("F-", "A+", "A++"))) |> 
  pull(marks)

marks_database_expand |> 
  fct_relevel(c("F-", "F", "E", "D", "C", "B", "A", "A+", "A++"))
  
```


---

## Quali: factors

:::: columns
::: {.column width="55%"}

This way of working with qualitative variables allows us to give a [**theoretical definition**]{.hl-yellow} of our database, and we can even count values that do not yet exist (but could), making use of `fct_count()`.

:::

::: {.column width="45%"}


```{r echo = FALSE,  out.width = "70%", fig.align = "left"}
knitr::include_graphics("./img/fct_count.jpg")
``` 

:::
::::

```{r}
marks_database |> 
  mutate(marks = fct_expand(marks, c("F-", "A+", "A++"))) |> 
  pull(marks) |> 
  fct_count()
```


---

## Quali: factors

The levels can also be [**sorted by frequency**]{.hl-yellow} with `fct_infreq()`.

```{r}
marks_database |> 
  mutate(marks = fct_infreq(marks)) |> 
  pull(marks)

marks_database |> 
  mutate(marks = fct_infreq(marks)) |> 
  pull(marks) |> 
  fct_count()
```

---

## Quali: factors


Sometimes we will want to [**group levels**]{.hl-yellow}, for example, not allowing levels that [**do not happen a minimum number of times**]{.hl-yellow} with `fct_lump_min(..., min = ..)` (observations that do not meet this will go to a **generic level** called `Other`, although this can be changed with the `other_level` argument). 

:::: columns
::: {.column width="50%"}


```{r}
marks_database |> 
  pull(marks) %>% 
  fct_lump_min(min = 3)
```

:::

::: {.column width="50%"}


```{r}
marks_database |> 
  pull(marks) |>
  fct_lump_min(min = 3,
               other_level = "Less frequent")
```

:::
::::

---

## Quali: factors


We can do something equivalent but based on its [**relative frequency**]{.hl-yellow} with `fct_lump_prop()`.


```{r}
marks_database |> 
  pull(marks) |> 
  fct_lump_prop(prop = 0.15,
                other_level = "less frequent")
```

---


## Quali: factors

We can apply this to our datasets to [**recategorize variables**]{.hl-yellow} very quickly.

```{r}
starwars |>  
  drop_na(species) |> 
  mutate(species =
           fct_lump_min(species, min = 3,
                        other_level = "Others")) |>  
  count(species)
```

---

## Quali: factors



With `fct_reorder()` we can also indicate that we want to [**order the factors**]{.hl-yellow} according to a function applied to another variable.


```{r}
starwars_factor <- 
  starwars |>  
  drop_na(height, species) |> 
  mutate(species =
           fct_lump_min(species, min = 3,
                        other_level = "Others"))
```

:::: columns
::: {.column width="50%"}


```{r}
starwars_factor |>  pull(species)
```

:::

::: {.column width="50%"}


```{r}
starwars_factor |> 
  mutate(species = fct_reorder(species, height, mean)) |> 
  pull(species)
```

:::
::::


---

## 💻 Your turn


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Given the variable `months` defined below (defined as a character vector), convert this variable to factor (just that)

```{r}
months <- c("Jan", "Feb", "Mar", "Apr")
```

```{r}
#| code-fold: true
#| eval: false
months <- c("Jan", "Feb", "Mar", "Apr")
months_fct <- as_factor(months)
months_fct
```

### [**Exercise 2**]{.hl-yellow}

📝 Given the variable `months` defined below converts this variable to a factor but indicating the levels correctly.

```{r}
months <- c(NA, "Apr", "Jan", "Oct", "Jul", "Jan", "Sep", NA, "Feb", "Dic",
           "Jul", "Mar", "Jan", "Mar", "Feb", "Apr", "May", "Oct", "Sep",  NA,
           "Dic", "Jul", "Nov", "Feb", "Oct", "Jun", "Sep", "Oct", "Oct", "Sep")
```



```{r}
#| code-fold: true
#| eval: false
months_fct <-
  factor(months,
         levels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dic"))
months_fct
```

  
### [**Exercise 3**]{.hl-yellow}

📝 Count how many values there are for each month but keep in mind that they are factors (maybe there are unused levels and you should get a 0 for them).


```{r}
#| code-fold: true
#| eval: false
meses_fct |>  fct_count()
```

### [**Exercise 4**]{.hl-yellow}

📝 Since there are missing values, it indicates that the absentee is a thirteenth level labeled `"missing"`.

```{r}
#| code-fold: true
#| eval: false
months_fct <- 
  months_fct |> 
  fct_explicit_na(na_level = "missing")
months_fct
```

### [**Exercise 5**]{.hl-yellow}

📝 Removes unused levels.


```{r}
#| code-fold: true
#| eval: false
months_fct <- 
  months_fct %>%
  fct_drop()
months_fct
```


### [**Exercise 6**]{.hl-yellow}

📝 Sort the levels by frequency of occurrence.


```{r}
#| code-fold: true
#| eval: false
months_fct |> 
  fct_infreq()
```

### [**Exercise 7**]{.hl-yellow}

📝 Group levels so that any level that does not appear at least 7% of the time is grouped in a level called `"other months"`.
  
```{r}
#| code-fold: true
#| eval: false
months_fct <-
  months_fct |> 
  fct_lump_prop(prop = 0.07, other_level = "other months")
months_fct 
```

:::



# Lesson 9: lists, joins and SQL {#clase-9}

[**Lists. Joins and SQL connection**]{style="color:#444442;"}

---

## Lists

We have already seen that lists are an object in R that allows us to store [**collections of variables of different type**]{.hl-yellow} (as with `data.frame` and `tibble`) but also [**different lengths**]{.hl-purple}, with totally heterogeneous structures (even a list can have inside it another list).

```{r}
name <- "Javi"
age <- 34
marks <- c(7, 8, 5, 3, 10, 9)
parents <- c("Paloma", "Goyo")

list_var <- list("name" = name, "age" = age, "marks" = marks, "parents" = parents)
```


```{r}
list_var$name
list_var$marks
```



---

## Lists


We can also make [**lists with other lists inside**]{.hl-yellow}, so that to access each level we must use the `[[]]` operator.

```{r}
list_of_lists <- list("list_1" = list_var[1:2], "list_2" = list_var[3:4])
names(list_of_lists)
```

```{r}
names(list_of_lists[[1]])
```

```{r}
list_of_lists[[1]][[1]]
```

. . .

We are allowed to store [**n-dimensional data**]{.hl-yellow}!

---

## Lists

One of the disadvantages is that a list [**cannot be vectorized**]{.hl-yellow} immediately, so any arithmetic operation applied to a list will give [**error**]{.hl-red}.

```{r}
#| error: true
data <- list("a" = 1:5, "b" = 10:20)
data / 2
```

. . .

For this purpose, one of the common (but outdated) options is to make use of the `lapply()` family.

```{r}
lapply(data, FUN = function(x) { x / 2})
```

By default, the output of `lapply()`is always a [**list of equal length**]{.hl-yellow}.

---

## Lists


A more flexible and versatile option is to make use of the `{purrr}` package of the `{tidyverse}` environment.

```{r}
library(purrr)
```

This package is intended to mimic the [**functional programming**]{.hl-yellow} of other languages such as Scala or Hadoop's [**map-reduce strategy**]{.hl-yellow} (from Google).

![](img/purrr.png)

---

## Lists

The simplest function of the `{purrr}` package is the `map()` function, which [**applies a vectorized function**]{.hl-yellow} to each of the elements of a list. Let's see a first example applied to vectors

. . .

`map()` allows us to [**"map" each list**]{.hl-yellow} and apply the function element by element (if applicable).

```{r}
x <- list("x1" = 1:4, "x2" = 11:20)
map(x, sqrt) 
```

. . .


::: callout-warning
## Be careful

With vectors we have a default vectorization because `R` performs element-by-element operations. Note that, by default, the [**output of `map` is a list**]{.hl-yellow}.
:::


---

## Lists

Let's look at another example. Define in a list two samples from 2 normal distributions, of different sample size and different mean. Compute the mean of each one.

```{r}
#| code-fold: true
x <- list(rnorm(n = 1500, mean = 0, sd = 0.7),
          rnorm(n = 2800, mean = 2, sd = 1.5))
map(x, mean)
```

---

## Lists

What if we want to calculate the mean of their squared values?

```{r}
#| code-fold: true
map(x, function(x) { mean(x^2) })
```


---

## Lists

In addition to being [**more readable and efficient**]{.hl-yellow}, with `{purrr}` we can [**decide the output format**]{.hl-yellow} after the operation

* output as [**numeric (double) vector**]{.hl-purple} with `map_dbl()`
* output as [**numeric (int) vector**]{.hl-purple} with `map_int()`
* output as [**character vector**]{.hl-purple} with `map_chr()`
* output as [**logical vector**]{.hl-purple} with `map_lgl()`

```{r}
map_dbl(x, mean)
map_chr(x, function(x) { glue("Mean is {round(mean(x), 5)}") })
```

---

## Lists

```{r}
c(x[[1]][3], x[[2]][3])
```


Also, if you pass it a [**number**]{.hl-yellow} instead of a function, it will return the [**ith element of each list**]{.hl-yellow}.

```{r}
map_dbl(x, 3)
```


---


## Lists

We also have the option of generalizing it to be able to use functions that [**need two arguments in the form of a list**]{.hl-yellow} (binary operations), with `map2()`


```{r}
x <- list("a" = 1:3, "b" = 4:6)
y <- list("c" = c(-1, 4, 0), "b" = c(5, -4, -1))
map2(x, y, function(x, y) { x^2 + y^2})
```

---

## Lists

We can obtain the output in the form of `data.frame` by adding `list_rbind()` or `list_cbind()`, which [**converts a list into a table**]{.hl-yellow}.


```{r}
x <- c("a", "b", "c")
y <- 1:3
map2(x, y, function(x, y) { tibble(x, y) }) |> list_rbind()
```

---

## Lists

We can generalize it further with `pmap_xxx()` which allows us to use [**multiple arguments (multiple lists)**]{.hl-yellow}.


```{r}
x <- list(1, 1, 1)
y <- list(10, 20, 30)
z <- list(100, 200, 300)
pmap_dbl(list(x, y, z), sum)
```

---

## Lists

We have other types of iterators that, although they assume inputs, do not return anything, as `walk()` (just one input argument), `walk2()` (two arguments) and `pwalk()` (multiple arguments), all [**invisibly return**]{.hl-yellow}, just call a function for its [**side effects**]{.hl-yellow} rather than its return value.

```{r}
list("a" = 1:3, "b" = 4:6) |>
  map2(list("a" = 11:13, "b" = 14:16),
       function(x, y) { x + y }) |> 
  walk(print)
```

---

## 💻 Your turn


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 Define a list of 4 elements of different types and access the second of them (I will include one that is a tibble so that you can see that in a list there is room for everything).

```{r}
#| code-fold: true
#| eval: false
list_example <-
  list("name" = "Javier", "cp" = 28019,
       "siblings" = TRUE,
       "marks" = tibble("maths" = c(7.5, 8, 9),
                        "lang" = c(10, 5, 6)))
list_example
```

### [**Exercise 2**]{.hl-yellow}

📝 From the list above, access the elements that occupy places 1 and 4 of the list defined above.

```{r}
#| code-fold: true
#| eval: false

list_example[c(1, 4)]

list_example$name
list_example$marks

list_example[c("name", "marks")]
```



### [**Exercise 3**]{.hl-yellow}

📝  Load the `starwars` dataset from the `{dplyr}` package and access the second movie that appears in `starwars$films` (for each character). Determine which ones do not appear in more than one movie.

```{r}
second_film <- map(starwars$films, 2)
map_lgl(second_film, is.null)
```

:::


---

## Joins

When working with data we will not always have the information in a single table, and sometimes, we will be interested in [**cross-referencing**]{.hl-yellow} information from different sources.

. . .

For this we will use a classic of every language that handles data: the famous [**join**]{.hl-yellow}, a tool that will allow us to [**cross one or several tables**]{.hl-yellow}, making use of a [**identifying column**]{.hl-yellow} of each one of them.

```{r}
#| eval: false
table_1 |>
  xxx_join(table_2, by = id)
```

---

## Joins

* `inner_join()`: only [**records with id in both**]{.hl-yellow} tables survive.

* `full_join()`: keeps [**all records in both**]{.hl-yellow} tables.

* `left_join()`: keeps [**all the records of the first table**]{.hl-yellow}, and looks for which ones have id also in the second one (in case of [**not having it, it fills with NA**]{.hl-yellow} the fields of the 2nd table).

* `right_join()`: keeps [**all records in the second table**]{.hl-yellow}, and searches which ones have id also in the first one.

![](img/sql-joins.jpg)    



---

## Joins

Let's test the various joins with a simple example

```{r}
tb_1 <- tibble("key" = 1:3, "val_x" = c("x1", "x2", "x3"))
tb_2 <- tibble("key" = c(1, 2, 4), "val_y" = c("y1", "y2", "y3"))
```

:::: columns
::: {.column width="50%"}

```{r}
tb_1
```

:::

::: {.column width="50%"}

```{r}
tb_2
```

:::
::::

---


## left_join()

Imagine that we want to [**incorporate**]{.hl-yellow} to `tb_1` the [**information from table_2**]{.hl-yellow}, identifying the records by the key column (`by = "key"`, the column it has to cross): we want to keep all the records of the first table and look for which ones have the same value in `key` also in the second one.

. . .

:::: columns
::: {.column width="50%"}

```{r}
tb_1 |> 
  left_join(tb_2, by = "key")
```

:::

::: {.column width="50%"}

![](img/left_join.jpg)

:::
::::



---

## left_join()


```{r}
tb_1 |>
  left_join(tb_2, by = "key")
```

Notice that the [**records in the first one whose key was not found in the second one**]{.hl-yellow} has given them the value of [**absent**]{.hl-yellow}.

---

## right_join()

The `right_join()` will perform the opposite operation: we will now [**incorporate**]{.hl-yellow} to `tb_2` the [**information from table_2**]{.hl-yellow}, identifying the records by the `key` column: we want to keep all the records of the second one and look for which ones have id (same value in `key`) also in the first table.

. . .

:::: columns
::: {.column width="50%"}


```{r}
tb_1 |> 
  right_join(tb_2, by = "key")
```

:::

::: {.column width="50%"}


![](img/right_join.jpg)

:::
::::


---

## right_join()


```{r}
tb_1 |>
  right_join(tb_2, by = "key")
```

Notice that now the [**records of the second one whose key was not found in the first one**]{.hl-yellow} are the ones given the value of [**absent**]{.hl-yellow}.

---

## keys and suffixes

The key columns we will use for the crossover [**will not always be named the same**]{.hl-yellow}.

```{r}
tb_1 <- tibble("key_1" = 1:3, "val_x" = c("x1", "x2", "x3"))
tb_2 <- tibble("key_2" = c(1, 2, 4), "val_y" = c("y1", "y2", "y3"))
```

. . .

* `by = c("key_2" = "key_2")`: we will indicate in which column of each table are the keys that we are going to cross.

:::: columns
::: {.column width="50%"}

```{r}
# Left
tb_1  |> 
  left_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

```{r}
# Right
tb_1 |> 
  right_join(tb_2, by = c("key_1" = "key_2"))
```

:::
::::


---

## keys and suffixes

We can also [**cross over several columns at the same time**]{.hl-yellow} (it will interpret as equal record the one that has the same set of keys), with `by = c("var1_t1" = "var1_t2", "var2_t1" = "var2_t2", ...)`. Let's modify the previous example

```{r}
tb_1 <- tibble("k_11" = 1:3, "k_12" = c("a", "b", "c"),  "val_x" = c("x1", "x2", "x3"))
tb_2 <- tibble("k_21" = c(1, 2, 4), "k_22" = c("a", "b", "e"), "val_y" = c("y1", "y2", "y3"))
```

. . .

:::: columns
::: {.column width="50%"}

```{r}
# Left
tb_1 |> 
  left_join(tb_2,
            by = c("k_11" = "k_21", "k_12" = "k_22"))
```

:::

::: {.column width="50%"}

```{r}
# Right
tb_1 |> 
  right_join(tb_2,
             by = c("k_11" = "k_21", "k_12" = "k_22"))
```

:::
::::

---

## keys and suffixes

It could also happen that when crossing two tables, there are [**columns of values named the same**]{.hl-yellow}

```{r}
tb_1 <- tibble("key_1" = 1:3, "val" = c("x1", "x2", "x3"))
tb_2 <- tibble("key_2" = c(1, 2, 4), "val" = c("y1", "y2", "y3"))
```

. . .

```{r}
# Left
tb_1 |>
  left_join(tb_2, by = c("key_1" = "key_2"))
```

Notice that [**default adds the suffixes**]{.hl-yellow} `.x` and `.y` to tell us which table they come from.

---

## keys and suffixes


This [**suffix can be specified**]{.hl-yellow} in the optional argument `suffix = ...`, which allows us to [**distinguish the variables**]{.hl-yellow} of one table from another.

```{r}
# Left
tb_1 |>
  left_join(tb_2, by = c("key_1" = "key_2"),
            suffix = c("_table1", "_table2"))
```

---

## full_join()

The two previous cases form what is known as [**outer joins**]{.hl-yellow}: crosses where observations are kept that appear in at least one table. The third outer join is known as `full_join()` which will [**keep observations from both**]{.hl-yellow} tables, [**adding rows**]{.hl-yellow} that do not match the other table.

:::: columns
::: {.column width="50%"}

```{r}
tb_1  |> 
  full_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

![](img/full_join.jpg)

:::
::::

---

## inner_join()

Opposite the outer join is what is known as [**inner join**]{.hl-yellow}, with `inner_join()`: a join in which only the [**observations that appear in both tables**]{.hl-yellow} are kept, only those records that are patched are kept.

:::: columns
::: {.column width="50%"}


```{r}
tb_1 |> 
  inner_join(tb_2,  by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

![](img/inner_join.png)

:::
::::



---

## inner_join()

Note that in terms of records, `inner_join` if it is commutative, **we don't care about the order of the tables**: the only thing that changes is the order of the columns it adds.

:::: columns
::: {.column width="50%"}


```{r}
tb_1 |> 
  inner_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

```{r}
tb_2 |> inner_join(tb_1, by = c("key_2" = "key_1"))
```

:::
::::

---

## semi/anti_join()

Finally we have two interesting tools to [**filter (not cross) records**]{.hl-yellow}: `semi_join()` and `anti_join()`. The [**semi join**]{.hl-yellow} leaves us in the [**first table the records whose key is also in the second table**]{.hl-yellow} (like an inner join but without adding the info from the second table). And the second one, the anti join, does just the opposite (those that are not).


:::: columns

::: {.column width="50%"}

```{r}
# semijoin
tb_1 |> 
  semi_join(tb_2, by = c("key_1" = "key_2"))
```

:::

::: {.column width="50%"}

```{r}
# antijoin
tb_1 |> 
  anti_join(tb_2, by = c("key_1" = "key_2"))
```

:::
::::

---

## 💻 Your turn

For the exercises we will use the tables available in the package `{nycflights13}`.

```{r}
library(nycflights13)
```

* **airlines**: name of airlines (with their abbreviation).
* **airports**: airport data (names, longitude, latitude, altitude, etc).
* **flights**, **planes**: flight and aircraft data.
* **weather**: hourly weather data.

---

## 💻 Your turn


::: panel-tabset

### [**Exercise 1**]{.hl-yellow}

📝 From package `{nycflights13}` incorporates into the `flights` table the airline data in `airlines`. We want to maintain all flight records, adding the airline information to the airlines table.


```{r}
#| code-fold: true
#| eval: false
flights_airlines <-
  flights |> 
  left_join(airlines, by = "carrier")
flights_airlines
```

### [**Exercise 2**]{.hl-yellow}

📝 To the table obtained from the crossing of the previous section, include the data of the aircraft in `planes`, but including only those flights for which we have information on their aircraft (and vice versa). 

```{r}
#| code-fold: true
#| eval: false

flights_airlines_planes <- 
  flights_airlines |> 
  inner_join(planes, by = "tailnum")
flights_airlines_planes
```


### [**Exercise 3**]{.hl-yellow}

📝 Repeat the previous exercise but keeping both `year` variables (in one is the year of flight, in the other is the year of construction of the aircraft), and distinguishing them from each other


```{r}
#| code-fold: true
#| eval: false

flights_airlines_planes <- 
  flights_airlines |>
  inner_join(planes, by = "tailnum",
             suffix = c("_flight", "_build_aircraft"))
flights_airlines_planes
```


### [**Exercise 4**]{.hl-yellow}

📝 To the table obtained from the previous exercise includes the longitude and latitude of the airports in `airports`, distinguishing between the latitude/longitude of the airport at destination and at origin.


```{r}
#| code-fold: true
#| eval: false

flights_airlines_planes |> 
  left_join(airports |> select(faa, lat, lon),
            by = c("origin" = "faa")) |> 
  rename(lat_origin = lat, lon_origin = lon) |> 
  left_join(airports |> select(faa, lat, lon),
            by = c("dest" = "faa")) |> 
  rename(lat_dest = lat, lon_dest = lon)
```

### [**Exercise 5**]{.hl-yellow}

📝 Filter from `airports` only those airports from which flights depart. Repeat the process filtering only those airports where flights arrive.


```{r}
#| code-fold: true
#| eval: false

airports |> 
  semi_join(flights, by = c("faa" = "origin"))
airports |> 
  semi_join(flights, by = c("faa" = "dest"))
```

### [**Exercise 6**]{.hl-yellow}

📝 How many flights do we not have information about the aircraft? Eliminate flights that do not have an aircraft ID (other than NA) beforehand.


```{r}
#| code-fold: true
#| eval: false

flights |>
  drop_na(tailnum) |>
  anti_join(planes, by = "tailnum") |>
  count(tailnum, sort = TRUE) 
```

:::


---

## dbplyr: SQL connection


Finally we are going to introduce the `{dbplyr}` package, which will allow us to combine `SQL` code into `R` to perform [**database queries**]{.hl-yellow}

```{r}
#| eval: false
install.packages("dbplyr")
```

&nbsp;

If you are using R to do data analysis, most of the data you need probably already lives in a database. We will learn how to [**load data in to a local database**]{.hl-yellow}.


---

## dbplyr: SQL connection

```{r}
#| eval: false
install.packages("RSQLite")
```


We will also need to install a [**DBI backend package**]{.hl-yellow} (an interface that allows `{dplyr}` to work with many different databases using the same code). Five commonly used backends are:

* `RMariaDB` connects to MySQL and MariaDB

* `RPostgres` connects to Postgres and Redshift.

* `RSQLite` embeds a SQLite database.

* `odbc` connects to many commercial databases via the open database connectivity protocol.

* `bigrquery` connects to Google’s BigQuery.

. . .

In the following, we are going to use the [**RSQLite backend**]{.hl-yellow} (automatically installed when you install `{dbplyr}`).

---

## dbplyr: SQL connection

If we want to [**work with a database adopting dplyr grammar**]{.hl-yellow}, we must first connect to it. The connection will be done by using `DBI::dbConnect()`. The arguments to `DBI::dbConnect()` vary from database to database, but the first argument is always the database backend. SQLite only needs a path to the database. 


```{r}
connection <- DBI::dbConnect(RSQLite::SQLite(), dbname = ":memory:")
connection
```

Here, the string `":memory:"` is a special path that creates [**a temporary in-memory database**]{.hl-yellow}.

---

## dbplyr: SQL connection

The temporary database previously created has no yet data in it. We will [**copy an existing database**]{.hl-yellow} (for example, `gapminder` from `{gapminder}` package) using `copy_to()`. Using `tbl()` we "obtain" the database (called as named in `copy_to()`).

The main difference is that not it is a [**remote source in a SQLite database**]{.hl-yellow}.

```{r}
copy_to(connection, gapminder::gapminder, overwrite = TRUE, name = "gapminder_database")
gapminder_db <- tbl(connection, "gapminder_database")
gapminder_db
```

---

## dbplyr: SQL connection


The main goal of `{dbplyr}` is to [**automatically generate SQL from `dplyr` grammar**]{.hl-yellow} that we are already familiar with.

```{r}
gapminder_db |>
  select(country, year, lifeExp)
```

---

## dbplyr: SQL connection



The most important difference between ordinary tibbles and remote database queries is that now [**our `R` code is translated into SQL and executed in the database on the remote server**]{.hl-yellow}, not in R on your local machine: it never pulls data into R unless you explicitly ask for it, [**delaying doing any work until the last possible moment**]{.hl-purple} (sends it to the database in one step).

. . .

It is not [**until we ask for the data**]{.hl-yellow} (writing `gapminder_query` in console, for example), `dplyr` verbs generates the SQL and requests the results from the database. 

```{r}
gapminder_query <- 
  gapminder_db |>
  select(country, year, lifeExp)
gapminder_query
```

---

## dbplyr: SQL connection

**What is happening behind the scenes?**

. . . 

`{dplyr} ` is [**translating our R code into SQL verbs**]{.hl-yellow}, that we can check (without doing) by using `show_query()`

```{r}
gapminder_query |> 
  show_query()
```

---

## dbplyr: SQL connection

As commented, our remote database queries is not in R on your local machine: it never pulls data into R unless you explicitly ask for it. To do it, you can iterate a few times before you figure out what data you need, and then we use `collect()`.

```{r}
gapminder_tibble <-
  gapminder_query |> 
  collect()
gapminder_tibble
```

---

## dbplyr: SQL connection

You can also use `translate_sql()` to translate individual expressions from `dplyr` to SQL

```{r}
dbplyr::translate_sql((x + y) / 2, con = connection)
```


# Thanks

[**Thanks! **]{style="color:#444442;"}



